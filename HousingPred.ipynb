{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\adb\\\\iCloudDrive\\\\Adnan PC\\\\Data Science\\\\Jupyter NB'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EDA import eda_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'.\\kaggle\\housing\\house-prices-advanced-regression-techniques\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Shape============================\n",
      "DataFrame Shape:  (1460, 81)\n",
      "=================INFO============================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     1452 non-null   object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n",
      "None\n",
      "=================Numerical============================\n",
      "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
      "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
      "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
      "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
      "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
      "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
      "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
      "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
      "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
      "\n",
      "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
      "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n",
      "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n",
      "std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n",
      "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
      "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n",
      "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n",
      "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n",
      "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n",
      "\n",
      "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
      "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
      "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
      "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
      "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
      "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
      "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
      "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
      "\n",
      "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
      "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
      "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
      "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
      "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
      "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
      "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
      "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
      "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
      "\n",
      "[8 rows x 38 columns]\n",
      "=================Missing Values============================\n",
      "Features missing more than 40% data:  5\n",
      "['Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature']\n",
      "=================Unique Values============================\n",
      "1 . CentralAir ['Y' 'N']\n",
      "2 . Utilities ['AllPub' 'NoSeWa']\n",
      "3 . Street ['Pave' 'Grvl']\n",
      "4 . Alley [nan 'Grvl' 'Pave']\n",
      "5 . BsmtHalfBath [0 1 2]\n",
      "6 . LandSlope ['Gtl' 'Mod' 'Sev']\n",
      "7 . GarageFinish ['RFn' 'Unf' 'Fin' nan]\n",
      "8 . HalfBath [1 0 2]\n",
      "9 . PavedDrive ['Y' 'N' 'P']\n",
      "10 . PoolQC [nan 'Ex' 'Fa' 'Gd']\n",
      "11 . FullBath [2 1 3 0]\n",
      "12 . MasVnrType ['BrkFace' 'None' 'Stone' 'BrkCmn' nan]\n",
      "13 . BsmtExposure ['No' 'Gd' 'Mn' 'Av' nan]\n",
      "14 . ExterQual ['Gd' 'TA' 'Ex' 'Fa']\n",
      "15 . MiscFeature [nan 'Shed' 'Gar2' 'Othr' 'TenC']\n",
      "16 . BsmtFullBath [1 0 2 3]\n",
      "17 . Fence [nan 'MnPrv' 'GdWo' 'GdPrv' 'MnWw']\n",
      "18 . KitchenQual ['Gd' 'TA' 'Ex' 'Fa']\n",
      "19 . BsmtCond ['TA' 'Gd' nan 'Fa' 'Po']\n",
      "20 . Fireplaces [0 1 2 3]\n",
      "21 . LandContour ['Lvl' 'Bnk' 'Low' 'HLS']\n",
      "22 . LotShape ['Reg' 'IR1' 'IR2' 'IR3']\n",
      "23 . KitchenAbvGr [1 2 3 0]\n",
      "24 . BsmtQual ['Gd' 'TA' 'Ex' nan 'Fa']\n",
      "25 . FireplaceQu [nan 'TA' 'Gd' 'Fa' 'Ex' 'Po']\n",
      "26 . Electrical ['SBrkr' 'FuseF' 'FuseA' 'FuseP' 'Mix' nan]\n",
      "27 . YrSold [2008 2007 2006 2009 2010]\n",
      "28 . GarageCars [2 3 1 0 4]\n",
      "29 . GarageQual ['TA' 'Fa' 'Gd' nan 'Ex' 'Po']\n",
      "30 . GarageCond ['TA' 'Fa' nan 'Gd' 'Po' 'Ex']\n",
      "31 . HeatingQC ['Ex' 'Gd' 'TA' 'Fa' 'Po']\n",
      "32 . ExterCond ['TA' 'Gd' 'Fa' 'Po' 'Ex']\n",
      "33 . MSZoning ['RL' 'RM' 'C (all)' 'FV' 'RH']\n",
      "34 . LotConfig ['Inside' 'FR2' 'Corner' 'CulDSac' 'FR3']\n",
      "35 . BldgType ['1Fam' '2fmCon' 'Duplex' 'TwnhsE' 'Twnhs']\n",
      "36 . BsmtFinType2 ['Unf' 'BLQ' nan 'ALQ' 'Rec' 'LwQ' 'GLQ']\n",
      "37 . Foundation ['PConc' 'CBlock' 'BrkTil' 'Wood' 'Slab' 'Stone']\n",
      "38 . RoofStyle ['Gable' 'Hip' 'Gambrel' 'Mansard' 'Flat' 'Shed']\n",
      "39 . SaleCondition ['Normal' 'Abnorml' 'Partial' 'AdjLand' 'Alloca' 'Family']\n",
      "40 . GarageType ['Attchd' 'Detchd' 'BuiltIn' 'CarPort' nan 'Basment' '2Types']\n",
      "41 . BsmtFinType1 ['GLQ' 'ALQ' 'Unf' 'Rec' 'BLQ' nan 'LwQ']\n",
      "42 . Heating ['GasA' 'GasW' 'Grav' 'Wall' 'OthW' 'Floor']\n",
      "43 . Functional ['Typ' 'Min1' 'Maj1' 'Min2' 'Mod' 'Maj2' 'Sev']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 . RoofMatl ['CompShg' 'WdShngl' 'Metal' 'WdShake' 'Membran' 'Tar&Grv' 'Roll'\n",
      " 'ClyTile']\n",
      "45 . HouseStyle ['2Story' '1Story' '1.5Fin' '1.5Unf' 'SFoyer' 'SLvl' '2.5Unf' '2.5Fin']\n",
      "46 . Condition2 ['Norm' 'Artery' 'RRNn' 'Feedr' 'PosN' 'PosA' 'RRAn' 'RRAe']\n",
      "47 . PoolArea [  0 512 648 576 555 480 519 738]\n",
      "48 . BedroomAbvGr [3 4 1 2 0 5 6 8]\n",
      "49 . SaleType ['WD' 'New' 'COD' 'ConLD' 'ConLI' 'CWD' 'ConLw' 'Con' 'Oth']\n",
      "50 . Condition1 ['Norm' 'Feedr' 'PosN' 'Artery' 'RRAe' 'RRNn' 'RRAn' 'PosA' 'RRNe']\n",
      "51 . OverallCond [5 8 6 7 4 2 3 9 1]\n",
      "52 . OverallQual [ 7  6  8  5  9  4 10  3  1  2]\n",
      "53 . TotRmsAbvGrd [ 8  6  7  9  5 11  4 10 12  3  2 14]\n",
      "54 . MoSold [ 2  5  9 12 10  8 11  4  1  7  3  6]\n"
     ]
    }
   ],
   "source": [
    "eda_df(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.iloc[:,:-1]\n",
    "train_y = train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = list(train_X.describe().columns)\n",
    "cat_col = list(set(train_X.columns).difference(num_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 43 37\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X.columns),len(cat_col),len(num_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_df(df):\n",
    "    assert(len(df.columns)==80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "new_col_list = []\n",
    "dropped_col_list = []\n",
    "df = train_X.copy()\n",
    "na_count_series = df.isna().mean()\n",
    "dropped_col_list = na_count_series[na_count_series>.4].index.to_list()\n",
    "\n",
    "        \n",
    "def col_remove(df):\n",
    "    global new_col_list\n",
    "    global dropped_col_list\n",
    "    for col in dropped_col_list:\n",
    "        if col in df.columns:\n",
    "            df = df.drop(columns=col,axis=1)\n",
    "    new_col_list = list(set(df.columns).difference(dropped_col_list))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_na(X):\n",
    "    X = X.fillna(X.mode().iloc[0])\n",
    "    return np.c_[X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "num_Pipeline = Pipeline([\n",
    "#     ('attr_rem',FunctionTransformer(col_remove,validate=False)),\n",
    "    ('fill_na',FunctionTransformer(fix_na,validate=False)),\n",
    "    ('imputer',SimpleImputer(strategy='median')),\n",
    "    ('std_scaler',StandardScaler()),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_Pipeline = Pipeline([\n",
    "#     ('attr_rem',FunctionTransformer(col_remove,validate=False)),\n",
    "    ('fill_na',FunctionTransformer(fix_na,validate=False)),    \n",
    "    ('cat_enc',OneHotEncoder())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "full_Pipeline = ColumnTransformer([\n",
    "    ('num',num_Pipeline,num_col),\n",
    "    ('cat',cat_Pipeline,cat_col),\n",
    "])\n",
    "\n",
    "housing_preproc = full_Pipeline.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116800"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_preproc.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = housing_preproc\n",
    "y= train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81723043 0.82177606 0.80300543 0.88821732 0.64508627]\n",
      "0.7950631019439506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lr = LinearRegression()\n",
    "cv = cross_val_score(lr,X,y)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adb\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0239726  0.00342466 0.01369863 0.01712329 0.00342466]\n",
      "0.012328767123287671\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "cv = cross_val_score(log_reg,X,y)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70579727 0.74042153 0.83738121 0.75509043 0.65520805]\n",
      "0.738779699404774\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "cv = cross_val_score(tree_reg,X,y)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(tree_reg, X, y,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [36132.31461833 40371.0448103  36516.10875213 43665.81705917\n",
      " 38155.74187082 28367.12891301 34140.60112733 34957.0746815\n",
      " 48492.81398084 36238.879841  ]\n",
      "Mean: 37703.75256544255\n",
      "Standard deviation: 5222.139383896559\n"
     ]
    }
   ],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [24110.54335233 35253.24867128 23310.63175753 41612.96532634\n",
      " 30574.53565328 43472.56647212 24163.65138133 22662.15218288\n",
      " 66662.72690708 22248.26976286]\n",
      "Mean: 33407.129146703686\n",
      "Standard deviation: 13415.653627085188\n"
     ]
    }
   ],
   "source": [
    "lin_scores = cross_val_score(lr, X, y,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\adb\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\adb\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\adb\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\adb\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\adb\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\adb\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\adb\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\adb\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\adb\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\adb\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\adb\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\adb\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               37120     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 70,401\n",
      "Trainable params: 70,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Input Layer\n",
    "model.add(Dense(128,kernel_initializer='normal',input_dim=X.shape[1],activation='relu'))\n",
    "model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(1,kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "model.compile(loss='mean_absolute_error',optimizer='adam',metrics=['mean_absolute_error'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\adb\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1168 samples, validate on 292 samples\n",
      "Epoch 1/500\n",
      "1168/1168 [==============================] - 0s 184us/step - loss: 180570.1729 - mean_absolute_error: 180570.1875 - val_loss: 182161.2735 - val_mean_absolute_error: 182161.2656\n",
      "Epoch 2/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 180207.5599 - mean_absolute_error: 180207.5625 - val_loss: 181326.8104 - val_mean_absolute_error: 181326.8125\n",
      "Epoch 3/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 178357.7352 - mean_absolute_error: 178357.7344 - val_loss: 178209.1929 - val_mean_absolute_error: 178209.1875\n",
      "Epoch 4/500\n",
      "1168/1168 [==============================] - 0s 75us/step - loss: 173143.5201 - mean_absolute_error: 173143.5000 - val_loss: 170805.2568 - val_mean_absolute_error: 170805.2656\n",
      "Epoch 5/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 162400.1107 - mean_absolute_error: 162400.0938 - val_loss: 157008.6616 - val_mean_absolute_error: 157008.6562\n",
      "Epoch 6/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 143942.6353 - mean_absolute_error: 143942.6406 - val_loss: 134784.9133 - val_mean_absolute_error: 134784.9062\n",
      "Epoch 7/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 116116.7335 - mean_absolute_error: 116116.7266 - val_loss: 103051.7266 - val_mean_absolute_error: 103051.7266\n",
      "Epoch 8/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 81272.1527 - mean_absolute_error: 81272.1484 - val_loss: 67737.6676 - val_mean_absolute_error: 67737.6641\n",
      "Epoch 9/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 54431.2431 - mean_absolute_error: 54431.2422 - val_loss: 48629.8288 - val_mean_absolute_error: 48629.8281\n",
      "Epoch 10/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 43422.5591 - mean_absolute_error: 43422.5586 - val_loss: 41415.0096 - val_mean_absolute_error: 41415.0078\n",
      "Epoch 11/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 37376.1638 - mean_absolute_error: 37376.1602 - val_loss: 36594.4518 - val_mean_absolute_error: 36594.4570\n",
      "Epoch 12/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 32643.4521 - mean_absolute_error: 32643.4492 - val_loss: 32804.4690 - val_mean_absolute_error: 32804.4648\n",
      "Epoch 13/500\n",
      "1168/1168 [==============================] - 0s 74us/step - loss: 28979.1709 - mean_absolute_error: 28979.1719 - val_loss: 30136.6663 - val_mean_absolute_error: 30136.6641\n",
      "Epoch 14/500\n",
      "1168/1168 [==============================] - 0s 75us/step - loss: 26188.7478 - mean_absolute_error: 26188.7480 - val_loss: 27993.0962 - val_mean_absolute_error: 27993.0957\n",
      "Epoch 15/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 24216.5780 - mean_absolute_error: 24216.5762 - val_loss: 27114.6355 - val_mean_absolute_error: 27114.6348\n",
      "Epoch 16/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 23003.4997 - mean_absolute_error: 23003.5000 - val_loss: 25930.2835 - val_mean_absolute_error: 25930.2852\n",
      "Epoch 17/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 22095.0190 - mean_absolute_error: 22095.0195 - val_loss: 25125.8669 - val_mean_absolute_error: 25125.8652\n",
      "Epoch 18/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 21401.0161 - mean_absolute_error: 21401.0137 - val_loss: 24569.4794 - val_mean_absolute_error: 24569.4805\n",
      "Epoch 19/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 20845.6811 - mean_absolute_error: 20845.6816 - val_loss: 24055.7922 - val_mean_absolute_error: 24055.7930\n",
      "Epoch 20/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 20363.1356 - mean_absolute_error: 20363.1348 - val_loss: 23555.4819 - val_mean_absolute_error: 23555.4805\n",
      "Epoch 21/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 19908.3535 - mean_absolute_error: 19908.3535 - val_loss: 23425.9071 - val_mean_absolute_error: 23425.9062\n",
      "Epoch 22/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 19520.6659 - mean_absolute_error: 19520.6660 - val_loss: 23252.7647 - val_mean_absolute_error: 23252.7656\n",
      "Epoch 23/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 19190.9418 - mean_absolute_error: 19190.9395 - val_loss: 22738.1032 - val_mean_absolute_error: 22738.1016\n",
      "Epoch 24/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 18825.5931 - mean_absolute_error: 18825.5918 - val_loss: 22397.8572 - val_mean_absolute_error: 22397.8574\n",
      "Epoch 25/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 18559.3912 - mean_absolute_error: 18559.3906 - val_loss: 22071.3991 - val_mean_absolute_error: 22071.3984\n",
      "Epoch 26/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 18234.8201 - mean_absolute_error: 18234.8223 - val_loss: 22053.8486 - val_mean_absolute_error: 22053.8496\n",
      "Epoch 27/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 18006.2771 - mean_absolute_error: 18006.2754 - val_loss: 21927.0740 - val_mean_absolute_error: 21927.0742\n",
      "Epoch 28/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 17755.5466 - mean_absolute_error: 17755.5488 - val_loss: 21625.0262 - val_mean_absolute_error: 21625.0273\n",
      "Epoch 29/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 17514.4093 - mean_absolute_error: 17514.4062 - val_loss: 21511.9152 - val_mean_absolute_error: 21511.9141\n",
      "Epoch 30/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 17256.3548 - mean_absolute_error: 17256.3535 - val_loss: 21206.1512 - val_mean_absolute_error: 21206.1504\n",
      "Epoch 31/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 17039.9836 - mean_absolute_error: 17039.9824 - val_loss: 21093.1772 - val_mean_absolute_error: 21093.1758\n",
      "Epoch 32/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 16845.0954 - mean_absolute_error: 16845.0918 - val_loss: 20927.7004 - val_mean_absolute_error: 20927.7012\n",
      "Epoch 33/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 16647.9319 - mean_absolute_error: 16647.9336 - val_loss: 20779.7616 - val_mean_absolute_error: 20779.7617\n",
      "Epoch 34/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 16489.2622 - mean_absolute_error: 16489.2578 - val_loss: 20605.4166 - val_mean_absolute_error: 20605.4160\n",
      "Epoch 35/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 16319.4599 - mean_absolute_error: 16319.4609 - val_loss: 20495.6198 - val_mean_absolute_error: 20495.6191\n",
      "Epoch 36/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 16182.9282 - mean_absolute_error: 16182.9277 - val_loss: 20389.5215 - val_mean_absolute_error: 20389.5215\n",
      "Epoch 37/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 16019.8516 - mean_absolute_error: 16019.8496 - val_loss: 20490.5638 - val_mean_absolute_error: 20490.5625\n",
      "Epoch 38/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 15949.4988 - mean_absolute_error: 15949.4961 - val_loss: 20211.4313 - val_mean_absolute_error: 20211.4316\n",
      "Epoch 39/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 15769.5204 - mean_absolute_error: 15769.5225 - val_loss: 20064.0899 - val_mean_absolute_error: 20064.0898\n",
      "Epoch 40/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 15645.6819 - mean_absolute_error: 15645.6836 - val_loss: 20007.8659 - val_mean_absolute_error: 20007.8672\n",
      "Epoch 41/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 15541.4693 - mean_absolute_error: 15541.4678 - val_loss: 19899.7471 - val_mean_absolute_error: 19899.7441\n",
      "Epoch 42/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 15454.9531 - mean_absolute_error: 15454.9551 - val_loss: 19810.9677 - val_mean_absolute_error: 19810.9688\n",
      "Epoch 43/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 15324.1301 - mean_absolute_error: 15324.1299 - val_loss: 19737.3000 - val_mean_absolute_error: 19737.2988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 15237.4060 - mean_absolute_error: 15237.4043 - val_loss: 19664.9007 - val_mean_absolute_error: 19664.9023\n",
      "Epoch 45/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 15157.8862 - mean_absolute_error: 15157.8867 - val_loss: 19653.8315 - val_mean_absolute_error: 19653.8301\n",
      "Epoch 46/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 15047.4764 - mean_absolute_error: 15047.4756 - val_loss: 19603.9361 - val_mean_absolute_error: 19603.9336\n",
      "Epoch 47/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 15054.6878 - mean_absolute_error: 15054.6885 - val_loss: 19505.1790 - val_mean_absolute_error: 19505.1777\n",
      "Epoch 48/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 14909.8517 - mean_absolute_error: 14909.8506 - val_loss: 19497.9693 - val_mean_absolute_error: 19497.9668\n",
      "Epoch 49/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 14876.7516 - mean_absolute_error: 14876.7500 - val_loss: 19371.8040 - val_mean_absolute_error: 19371.8047\n",
      "Epoch 50/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 14758.1726 - mean_absolute_error: 14758.1729 - val_loss: 19314.0659 - val_mean_absolute_error: 19314.0664\n",
      "Epoch 51/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 14749.4217 - mean_absolute_error: 14749.4229 - val_loss: 19380.3984 - val_mean_absolute_error: 19380.3965\n",
      "Epoch 52/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 14631.6604 - mean_absolute_error: 14631.6592 - val_loss: 19223.7715 - val_mean_absolute_error: 19223.7715\n",
      "Epoch 53/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 14572.2370 - mean_absolute_error: 14572.2344 - val_loss: 19194.3711 - val_mean_absolute_error: 19194.3711\n",
      "Epoch 54/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 14523.5067 - mean_absolute_error: 14523.5049 - val_loss: 19162.4761 - val_mean_absolute_error: 19162.4766\n",
      "Epoch 55/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 14473.4442 - mean_absolute_error: 14473.4453 - val_loss: 19103.7664 - val_mean_absolute_error: 19103.7656\n",
      "Epoch 56/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 14390.5825 - mean_absolute_error: 14390.5840 - val_loss: 19072.0448 - val_mean_absolute_error: 19072.0469\n",
      "Epoch 57/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 14347.2606 - mean_absolute_error: 14347.2617 - val_loss: 19030.0040 - val_mean_absolute_error: 19030.0059\n",
      "Epoch 58/500\n",
      "1168/1168 [==============================] - 0s 81us/step - loss: 14314.3920 - mean_absolute_error: 14314.3906 - val_loss: 19019.8027 - val_mean_absolute_error: 19019.8027\n",
      "Epoch 59/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 14244.9804 - mean_absolute_error: 14244.9814 - val_loss: 18943.2956 - val_mean_absolute_error: 18943.2949\n",
      "Epoch 60/500\n",
      "1168/1168 [==============================] - 0s 76us/step - loss: 14266.2473 - mean_absolute_error: 14266.2471 - val_loss: 18996.8723 - val_mean_absolute_error: 18996.8711\n",
      "Epoch 61/500\n",
      "1168/1168 [==============================] - 0s 74us/step - loss: 14225.7145 - mean_absolute_error: 14225.7139 - val_loss: 18906.7395 - val_mean_absolute_error: 18906.7422\n",
      "Epoch 62/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 14119.7029 - mean_absolute_error: 14119.7021 - val_loss: 18878.6477 - val_mean_absolute_error: 18878.6484\n",
      "Epoch 63/500\n",
      "1168/1168 [==============================] - 0s 74us/step - loss: 14072.3224 - mean_absolute_error: 14072.3223 - val_loss: 18820.6029 - val_mean_absolute_error: 18820.6035\n",
      "Epoch 64/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 14037.0012 - mean_absolute_error: 14037.0020 - val_loss: 18792.1169 - val_mean_absolute_error: 18792.1172\n",
      "Epoch 65/500\n",
      "1168/1168 [==============================] - 0s 74us/step - loss: 13999.3979 - mean_absolute_error: 13999.3975 - val_loss: 18758.2908 - val_mean_absolute_error: 18758.2910\n",
      "Epoch 66/500\n",
      "1168/1168 [==============================] - 0s 76us/step - loss: 13984.6383 - mean_absolute_error: 13984.6406 - val_loss: 18789.4286 - val_mean_absolute_error: 18789.4258\n",
      "Epoch 67/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 13953.9310 - mean_absolute_error: 13953.9326 - val_loss: 18777.5878 - val_mean_absolute_error: 18777.5879\n",
      "Epoch 68/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 13934.4127 - mean_absolute_error: 13934.4131 - val_loss: 18695.3816 - val_mean_absolute_error: 18695.3828\n",
      "Epoch 69/500\n",
      "1168/1168 [==============================] - 0s 75us/step - loss: 13878.4134 - mean_absolute_error: 13878.4121 - val_loss: 18668.3565 - val_mean_absolute_error: 18668.3555\n",
      "Epoch 70/500\n",
      "1168/1168 [==============================] - 0s 74us/step - loss: 13850.6640 - mean_absolute_error: 13850.6631 - val_loss: 18654.0046 - val_mean_absolute_error: 18654.0039\n",
      "Epoch 71/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 13841.9340 - mean_absolute_error: 13841.9336 - val_loss: 18629.4715 - val_mean_absolute_error: 18629.4727\n",
      "Epoch 72/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 13820.1078 - mean_absolute_error: 13820.1074 - val_loss: 18652.7590 - val_mean_absolute_error: 18652.7578\n",
      "Epoch 73/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 13825.5433 - mean_absolute_error: 13825.5430 - val_loss: 18593.4571 - val_mean_absolute_error: 18593.4590\n",
      "Epoch 74/500\n",
      "1168/1168 [==============================] - 0s 92us/step - loss: 13771.1997 - mean_absolute_error: 13771.2012 - val_loss: 18553.5893 - val_mean_absolute_error: 18553.5898\n",
      "Epoch 75/500\n",
      "1168/1168 [==============================] - 0s 85us/step - loss: 13734.1260 - mean_absolute_error: 13734.1289 - val_loss: 18563.2862 - val_mean_absolute_error: 18563.2852\n",
      "Epoch 76/500\n",
      "1168/1168 [==============================] - 0s 80us/step - loss: 13707.9550 - mean_absolute_error: 13707.9551 - val_loss: 18517.3158 - val_mean_absolute_error: 18517.3184\n",
      "Epoch 77/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 13676.1837 - mean_absolute_error: 13676.1836 - val_loss: 18509.2753 - val_mean_absolute_error: 18509.2734\n",
      "Epoch 78/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 13665.7821 - mean_absolute_error: 13665.7832 - val_loss: 18513.1153 - val_mean_absolute_error: 18513.1152\n",
      "Epoch 79/500\n",
      "1168/1168 [==============================] - 0s 80us/step - loss: 13641.4402 - mean_absolute_error: 13641.4404 - val_loss: 18502.8042 - val_mean_absolute_error: 18502.8066\n",
      "Epoch 80/500\n",
      "1168/1168 [==============================] - 0s 85us/step - loss: 13627.5867 - mean_absolute_error: 13627.5850 - val_loss: 18456.6863 - val_mean_absolute_error: 18456.6855\n",
      "Epoch 81/500\n",
      "1168/1168 [==============================] - 0s 82us/step - loss: 13661.0642 - mean_absolute_error: 13661.0664 - val_loss: 18466.7640 - val_mean_absolute_error: 18466.7637\n",
      "Epoch 82/500\n",
      "1168/1168 [==============================] - 0s 82us/step - loss: 13602.8168 - mean_absolute_error: 13602.8164 - val_loss: 18444.7289 - val_mean_absolute_error: 18444.7285\n",
      "Epoch 83/500\n",
      "1168/1168 [==============================] - 0s 78us/step - loss: 13588.0908 - mean_absolute_error: 13588.0898 - val_loss: 18388.3492 - val_mean_absolute_error: 18388.3496\n",
      "Epoch 84/500\n",
      "1168/1168 [==============================] - 0s 74us/step - loss: 13545.1865 - mean_absolute_error: 13545.1865 - val_loss: 18373.8147 - val_mean_absolute_error: 18373.8145\n",
      "Epoch 85/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 13527.2504 - mean_absolute_error: 13527.2510 - val_loss: 18359.7591 - val_mean_absolute_error: 18359.7578\n",
      "Epoch 86/500\n",
      "1168/1168 [==============================] - 0s 82us/step - loss: 13509.1883 - mean_absolute_error: 13509.1875 - val_loss: 18364.2136 - val_mean_absolute_error: 18364.2148\n",
      "Epoch 87/500\n",
      "1168/1168 [==============================] - 0s 82us/step - loss: 13491.5910 - mean_absolute_error: 13491.5898 - val_loss: 18383.3894 - val_mean_absolute_error: 18383.3906\n",
      "Epoch 88/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 73us/step - loss: 13458.3374 - mean_absolute_error: 13458.3398 - val_loss: 18363.7512 - val_mean_absolute_error: 18363.7520\n",
      "Epoch 89/500\n",
      "1168/1168 [==============================] - 0s 77us/step - loss: 13462.8120 - mean_absolute_error: 13462.8125 - val_loss: 18326.2408 - val_mean_absolute_error: 18326.2402\n",
      "Epoch 90/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 13443.2670 - mean_absolute_error: 13443.2676 - val_loss: 18305.3345 - val_mean_absolute_error: 18305.3359\n",
      "Epoch 91/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 13426.4406 - mean_absolute_error: 13426.4404 - val_loss: 18334.2962 - val_mean_absolute_error: 18334.2969\n",
      "Epoch 92/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 13454.2966 - mean_absolute_error: 13454.2979 - val_loss: 18352.3193 - val_mean_absolute_error: 18352.3184\n",
      "Epoch 93/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 13394.2568 - mean_absolute_error: 13394.2578 - val_loss: 18263.6570 - val_mean_absolute_error: 18263.6602\n",
      "Epoch 94/500\n",
      "1168/1168 [==============================] - 0s 78us/step - loss: 13386.9477 - mean_absolute_error: 13386.9482 - val_loss: 18290.1276 - val_mean_absolute_error: 18290.1289\n",
      "Epoch 95/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 13382.6256 - mean_absolute_error: 13382.6270 - val_loss: 18249.6802 - val_mean_absolute_error: 18249.6797\n",
      "Epoch 96/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 13360.2923 - mean_absolute_error: 13360.2930 - val_loss: 18215.4980 - val_mean_absolute_error: 18215.4980\n",
      "Epoch 97/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 13441.9944 - mean_absolute_error: 13441.9941 - val_loss: 18255.0109 - val_mean_absolute_error: 18255.0098\n",
      "Epoch 98/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 13325.4379 - mean_absolute_error: 13325.4375 - val_loss: 18204.3561 - val_mean_absolute_error: 18204.3555\n",
      "Epoch 99/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 13320.6565 - mean_absolute_error: 13320.6572 - val_loss: 18188.4150 - val_mean_absolute_error: 18188.4160\n",
      "Epoch 100/500\n",
      "1168/1168 [==============================] - 0s 77us/step - loss: 13281.4655 - mean_absolute_error: 13281.4658 - val_loss: 18217.6672 - val_mean_absolute_error: 18217.6680\n",
      "Epoch 101/500\n",
      "1168/1168 [==============================] - 0s 84us/step - loss: 13321.5500 - mean_absolute_error: 13321.5518 - val_loss: 18172.7909 - val_mean_absolute_error: 18172.7910\n",
      "Epoch 102/500\n",
      "1168/1168 [==============================] - 0s 82us/step - loss: 13274.2371 - mean_absolute_error: 13274.2373 - val_loss: 18170.1772 - val_mean_absolute_error: 18170.1758\n",
      "Epoch 103/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 13250.5311 - mean_absolute_error: 13250.5312 - val_loss: 18190.1533 - val_mean_absolute_error: 18190.1523\n",
      "Epoch 104/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 13243.1032 - mean_absolute_error: 13243.1016 - val_loss: 18154.7921 - val_mean_absolute_error: 18154.7949\n",
      "Epoch 105/500\n",
      "1168/1168 [==============================] - 0s 74us/step - loss: 13248.1689 - mean_absolute_error: 13248.1689 - val_loss: 18185.6973 - val_mean_absolute_error: 18185.6953\n",
      "Epoch 106/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 13234.2776 - mean_absolute_error: 13234.2764 - val_loss: 18112.8822 - val_mean_absolute_error: 18112.8828\n",
      "Epoch 107/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 13234.6775 - mean_absolute_error: 13234.6758 - val_loss: 18122.1713 - val_mean_absolute_error: 18122.1738\n",
      "Epoch 108/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 13219.0841 - mean_absolute_error: 13219.0859 - val_loss: 18161.3334 - val_mean_absolute_error: 18161.3340\n",
      "Epoch 109/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 13177.6944 - mean_absolute_error: 13177.6953 - val_loss: 18116.1073 - val_mean_absolute_error: 18116.1055\n",
      "Epoch 110/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 13177.3837 - mean_absolute_error: 13177.3838 - val_loss: 18112.7567 - val_mean_absolute_error: 18112.7578\n",
      "Epoch 111/500\n",
      "1168/1168 [==============================] - 0s 81us/step - loss: 13224.3526 - mean_absolute_error: 13224.3506 - val_loss: 18072.4041 - val_mean_absolute_error: 18072.4062\n",
      "Epoch 112/500\n",
      "1168/1168 [==============================] - 0s 81us/step - loss: 13140.0000 - mean_absolute_error: 13139.9980 - val_loss: 18066.7755 - val_mean_absolute_error: 18066.7734\n",
      "Epoch 113/500\n",
      "1168/1168 [==============================] - 0s 76us/step - loss: 13146.8167 - mean_absolute_error: 13146.8164 - val_loss: 18067.4806 - val_mean_absolute_error: 18067.4785\n",
      "Epoch 114/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 13159.9084 - mean_absolute_error: 13159.9092 - val_loss: 18056.6513 - val_mean_absolute_error: 18056.6504\n",
      "Epoch 115/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 13146.3292 - mean_absolute_error: 13146.3271 - val_loss: 18075.0135 - val_mean_absolute_error: 18075.0137\n",
      "Epoch 116/500\n",
      "1168/1168 [==============================] - 0s 76us/step - loss: 13131.0678 - mean_absolute_error: 13131.0703 - val_loss: 18060.1202 - val_mean_absolute_error: 18060.1191\n",
      "Epoch 117/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 13128.9685 - mean_absolute_error: 13128.9688 - val_loss: 18017.9097 - val_mean_absolute_error: 18017.9102\n",
      "Epoch 118/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 13109.3138 - mean_absolute_error: 13109.3164 - val_loss: 18016.7477 - val_mean_absolute_error: 18016.7461\n",
      "Epoch 119/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 13095.7848 - mean_absolute_error: 13095.7871 - val_loss: 17994.1849 - val_mean_absolute_error: 17994.1836\n",
      "Epoch 120/500\n",
      "1168/1168 [==============================] - 0s 75us/step - loss: 13095.9171 - mean_absolute_error: 13095.9170 - val_loss: 18044.6651 - val_mean_absolute_error: 18044.6660\n",
      "Epoch 121/500\n",
      "1168/1168 [==============================] - 0s 74us/step - loss: 13097.9062 - mean_absolute_error: 13097.9062 - val_loss: 18057.7825 - val_mean_absolute_error: 18057.7832\n",
      "Epoch 122/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 13100.2887 - mean_absolute_error: 13100.2881 - val_loss: 18013.2910 - val_mean_absolute_error: 18013.2910\n",
      "Epoch 123/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 13045.0083 - mean_absolute_error: 13045.0059 - val_loss: 18016.7118 - val_mean_absolute_error: 18016.7129\n",
      "Epoch 124/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 13039.8786 - mean_absolute_error: 13039.8779 - val_loss: 17994.4225 - val_mean_absolute_error: 17994.4219\n",
      "Epoch 125/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 13006.6517 - mean_absolute_error: 13006.6533 - val_loss: 17990.5867 - val_mean_absolute_error: 17990.5879\n",
      "Epoch 126/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 13006.6395 - mean_absolute_error: 13006.6387 - val_loss: 17987.5632 - val_mean_absolute_error: 17987.5625\n",
      "Epoch 127/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12999.0826 - mean_absolute_error: 12999.0820 - val_loss: 17980.4719 - val_mean_absolute_error: 17980.4727\n",
      "Epoch 128/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 12999.1792 - mean_absolute_error: 12999.1787 - val_loss: 18068.0476 - val_mean_absolute_error: 18068.0488\n",
      "Epoch 129/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 13027.4202 - mean_absolute_error: 13027.4180 - val_loss: 17950.2513 - val_mean_absolute_error: 17950.2520\n",
      "Epoch 130/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 13019.7288 - mean_absolute_error: 13019.7266 - val_loss: 17954.8528 - val_mean_absolute_error: 17954.8535\n",
      "Epoch 131/500\n",
      "1168/1168 [==============================] - 0s 77us/step - loss: 12979.8395 - mean_absolute_error: 12979.8408 - val_loss: 17973.3127 - val_mean_absolute_error: 17973.3145\n",
      "Epoch 132/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 68us/step - loss: 12982.9282 - mean_absolute_error: 12982.9297 - val_loss: 17961.7571 - val_mean_absolute_error: 17961.7539\n",
      "Epoch 133/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12985.2850 - mean_absolute_error: 12985.2861 - val_loss: 17972.3687 - val_mean_absolute_error: 17972.3691\n",
      "Epoch 134/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12947.3163 - mean_absolute_error: 12947.3154 - val_loss: 17957.1867 - val_mean_absolute_error: 17957.1875\n",
      "Epoch 135/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 12960.7489 - mean_absolute_error: 12960.7490 - val_loss: 17952.4698 - val_mean_absolute_error: 17952.4688\n",
      "Epoch 136/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12933.9339 - mean_absolute_error: 12933.9346 - val_loss: 17997.8042 - val_mean_absolute_error: 17997.8047\n",
      "Epoch 137/500\n",
      "1168/1168 [==============================] - 0s 78us/step - loss: 12948.8883 - mean_absolute_error: 12948.8867 - val_loss: 17949.1277 - val_mean_absolute_error: 17949.1289\n",
      "Epoch 138/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12951.7911 - mean_absolute_error: 12951.7920 - val_loss: 17983.3182 - val_mean_absolute_error: 17983.3164\n",
      "Epoch 139/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12929.2256 - mean_absolute_error: 12929.2256 - val_loss: 17937.4288 - val_mean_absolute_error: 17937.4297\n",
      "Epoch 140/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12918.6000 - mean_absolute_error: 12918.6006 - val_loss: 17946.9875 - val_mean_absolute_error: 17946.9883\n",
      "Epoch 141/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 12915.2892 - mean_absolute_error: 12915.2881 - val_loss: 17944.5513 - val_mean_absolute_error: 17944.5527\n",
      "Epoch 142/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12920.3134 - mean_absolute_error: 12920.3145 - val_loss: 17951.6046 - val_mean_absolute_error: 17951.6055\n",
      "Epoch 143/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12899.9350 - mean_absolute_error: 12899.9346 - val_loss: 17952.3303 - val_mean_absolute_error: 17952.3320\n",
      "Epoch 144/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12894.2963 - mean_absolute_error: 12894.2949 - val_loss: 17947.7834 - val_mean_absolute_error: 17947.7832\n",
      "Epoch 145/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12881.4971 - mean_absolute_error: 12881.4961 - val_loss: 17936.8222 - val_mean_absolute_error: 17936.8203\n",
      "Epoch 146/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12894.5256 - mean_absolute_error: 12894.5244 - val_loss: 17970.0829 - val_mean_absolute_error: 17970.0820\n",
      "Epoch 147/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12878.5894 - mean_absolute_error: 12878.5879 - val_loss: 17957.1948 - val_mean_absolute_error: 17957.1953\n",
      "Epoch 148/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12909.1070 - mean_absolute_error: 12909.1055 - val_loss: 17928.2308 - val_mean_absolute_error: 17928.2305\n",
      "Epoch 149/500\n",
      "1168/1168 [==============================] - 0s 74us/step - loss: 12908.2711 - mean_absolute_error: 12908.2705 - val_loss: 18044.0852 - val_mean_absolute_error: 18044.0859\n",
      "Epoch 150/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12860.3961 - mean_absolute_error: 12860.3975 - val_loss: 17925.2948 - val_mean_absolute_error: 17925.2930\n",
      "Epoch 151/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12852.6443 - mean_absolute_error: 12852.6436 - val_loss: 17951.1004 - val_mean_absolute_error: 17951.1016\n",
      "Epoch 152/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12826.9291 - mean_absolute_error: 12826.9268 - val_loss: 17965.8563 - val_mean_absolute_error: 17965.8535\n",
      "Epoch 153/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12839.2671 - mean_absolute_error: 12839.2666 - val_loss: 17914.4015 - val_mean_absolute_error: 17914.4004\n",
      "Epoch 154/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12830.3701 - mean_absolute_error: 12830.3711 - val_loss: 18007.8473 - val_mean_absolute_error: 18007.8477\n",
      "Epoch 155/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 12877.6211 - mean_absolute_error: 12877.6211 - val_loss: 17945.2169 - val_mean_absolute_error: 17945.2188\n",
      "Epoch 156/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12842.0947 - mean_absolute_error: 12842.0957 - val_loss: 17974.5827 - val_mean_absolute_error: 17974.5820\n",
      "Epoch 157/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12874.8694 - mean_absolute_error: 12874.8701 - val_loss: 17935.1888 - val_mean_absolute_error: 17935.1875\n",
      "Epoch 158/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12840.4895 - mean_absolute_error: 12840.4893 - val_loss: 17901.9833 - val_mean_absolute_error: 17901.9824\n",
      "Epoch 159/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12836.4001 - mean_absolute_error: 12836.4004 - val_loss: 17932.0323 - val_mean_absolute_error: 17932.0312\n",
      "Epoch 160/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12826.4074 - mean_absolute_error: 12826.4072 - val_loss: 17944.0760 - val_mean_absolute_error: 17944.0762\n",
      "Epoch 161/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12806.0650 - mean_absolute_error: 12806.0664 - val_loss: 17929.0063 - val_mean_absolute_error: 17929.0078\n",
      "Epoch 162/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12846.8910 - mean_absolute_error: 12846.8926 - val_loss: 17960.6350 - val_mean_absolute_error: 17960.6328\n",
      "Epoch 163/500\n",
      "1168/1168 [==============================] - 0s 74us/step - loss: 12789.2348 - mean_absolute_error: 12789.2334 - val_loss: 17947.5065 - val_mean_absolute_error: 17947.5078\n",
      "Epoch 164/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12784.6848 - mean_absolute_error: 12784.6846 - val_loss: 17964.6446 - val_mean_absolute_error: 17964.6445\n",
      "Epoch 165/500\n",
      "1168/1168 [==============================] - 0s 82us/step - loss: 12782.4111 - mean_absolute_error: 12782.4121 - val_loss: 17966.2117 - val_mean_absolute_error: 17966.2109\n",
      "Epoch 166/500\n",
      "1168/1168 [==============================] - 0s 83us/step - loss: 12781.8074 - mean_absolute_error: 12781.8086 - val_loss: 17934.9515 - val_mean_absolute_error: 17934.9512\n",
      "Epoch 167/500\n",
      "1168/1168 [==============================] - 0s 78us/step - loss: 12829.6467 - mean_absolute_error: 12829.6465 - val_loss: 17929.2677 - val_mean_absolute_error: 17929.2676\n",
      "Epoch 168/500\n",
      "1168/1168 [==============================] - 0s 77us/step - loss: 12806.4755 - mean_absolute_error: 12806.4756 - val_loss: 17988.8988 - val_mean_absolute_error: 17988.8984\n",
      "Epoch 169/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12793.7844 - mean_absolute_error: 12793.7871 - val_loss: 17970.4545 - val_mean_absolute_error: 17970.4512\n",
      "Epoch 170/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12755.7679 - mean_absolute_error: 12755.7676 - val_loss: 17967.2376 - val_mean_absolute_error: 17967.2363\n",
      "Epoch 171/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12797.3936 - mean_absolute_error: 12797.3926 - val_loss: 17906.9264 - val_mean_absolute_error: 17906.9258\n",
      "Epoch 172/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12745.9554 - mean_absolute_error: 12745.9551 - val_loss: 17978.2722 - val_mean_absolute_error: 17978.2715\n",
      "Epoch 173/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12770.0159 - mean_absolute_error: 12770.0156 - val_loss: 17918.9136 - val_mean_absolute_error: 17918.9121\n",
      "Epoch 174/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12782.3817 - mean_absolute_error: 12782.3818 - val_loss: 18027.9166 - val_mean_absolute_error: 18027.9180\n",
      "Epoch 175/500\n",
      "1168/1168 [==============================] - 0s 74us/step - loss: 12757.3806 - mean_absolute_error: 12757.3789 - val_loss: 17921.4469 - val_mean_absolute_error: 17921.4453\n",
      "Epoch 176/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 79us/step - loss: 12735.4571 - mean_absolute_error: 12735.4561 - val_loss: 17948.6732 - val_mean_absolute_error: 17948.6738\n",
      "Epoch 177/500\n",
      "1168/1168 [==============================] - 0s 85us/step - loss: 12724.3456 - mean_absolute_error: 12724.3467 - val_loss: 17978.3002 - val_mean_absolute_error: 17978.2988\n",
      "Epoch 178/500\n",
      "1168/1168 [==============================] - 0s 76us/step - loss: 12761.7334 - mean_absolute_error: 12761.7324 - val_loss: 17962.1763 - val_mean_absolute_error: 17962.1758\n",
      "Epoch 179/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12747.2285 - mean_absolute_error: 12747.2266 - val_loss: 17981.7251 - val_mean_absolute_error: 17981.7246\n",
      "Epoch 180/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12761.7300 - mean_absolute_error: 12761.7285 - val_loss: 18000.5808 - val_mean_absolute_error: 18000.5820\n",
      "Epoch 181/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12735.0566 - mean_absolute_error: 12735.0557 - val_loss: 18017.3451 - val_mean_absolute_error: 18017.3438\n",
      "Epoch 182/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12720.1082 - mean_absolute_error: 12720.1074 - val_loss: 17918.3286 - val_mean_absolute_error: 17918.3281\n",
      "Epoch 183/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12693.5330 - mean_absolute_error: 12693.5332 - val_loss: 18022.2913 - val_mean_absolute_error: 18022.2910\n",
      "Epoch 184/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12769.7662 - mean_absolute_error: 12769.7676 - val_loss: 17913.4402 - val_mean_absolute_error: 17913.4414\n",
      "Epoch 185/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12779.1768 - mean_absolute_error: 12779.1768 - val_loss: 17982.0688 - val_mean_absolute_error: 17982.0684\n",
      "Epoch 186/500\n",
      "1168/1168 [==============================] - 0s 77us/step - loss: 12739.4691 - mean_absolute_error: 12739.4688 - val_loss: 17915.4361 - val_mean_absolute_error: 17915.4375\n",
      "Epoch 187/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12701.6114 - mean_absolute_error: 12701.6113 - val_loss: 17929.5806 - val_mean_absolute_error: 17929.5801\n",
      "Epoch 188/500\n",
      "1168/1168 [==============================] - 0s 75us/step - loss: 12714.7138 - mean_absolute_error: 12714.7129 - val_loss: 18003.1179 - val_mean_absolute_error: 18003.1172\n",
      "Epoch 189/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12700.1107 - mean_absolute_error: 12700.1094 - val_loss: 17951.8696 - val_mean_absolute_error: 17951.8711\n",
      "Epoch 190/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12699.1035 - mean_absolute_error: 12699.1035 - val_loss: 17952.1147 - val_mean_absolute_error: 17952.1152\n",
      "Epoch 191/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12669.6502 - mean_absolute_error: 12669.6504 - val_loss: 18007.1869 - val_mean_absolute_error: 18007.1855\n",
      "Epoch 192/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12799.9348 - mean_absolute_error: 12799.9346 - val_loss: 17921.1941 - val_mean_absolute_error: 17921.1934\n",
      "Epoch 193/500\n",
      "1168/1168 [==============================] - 0s 78us/step - loss: 12709.7046 - mean_absolute_error: 12709.7041 - val_loss: 17947.8462 - val_mean_absolute_error: 17947.8438\n",
      "Epoch 194/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12694.4082 - mean_absolute_error: 12694.4062 - val_loss: 18118.6073 - val_mean_absolute_error: 18118.6055\n",
      "Epoch 195/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12682.2069 - mean_absolute_error: 12682.2090 - val_loss: 17949.2186 - val_mean_absolute_error: 17949.2168\n",
      "Epoch 196/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12664.0100 - mean_absolute_error: 12664.0098 - val_loss: 17967.3833 - val_mean_absolute_error: 17967.3828\n",
      "Epoch 197/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12680.8619 - mean_absolute_error: 12680.8613 - val_loss: 17965.5295 - val_mean_absolute_error: 17965.5293\n",
      "Epoch 198/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12683.7048 - mean_absolute_error: 12683.7051 - val_loss: 17935.5818 - val_mean_absolute_error: 17935.5801\n",
      "Epoch 199/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12690.2745 - mean_absolute_error: 12690.2754 - val_loss: 17956.4678 - val_mean_absolute_error: 17956.4688\n",
      "Epoch 200/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12642.5659 - mean_absolute_error: 12642.5654 - val_loss: 17987.0822 - val_mean_absolute_error: 17987.0840\n",
      "Epoch 201/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12684.1679 - mean_absolute_error: 12684.1689 - val_loss: 18018.1333 - val_mean_absolute_error: 18018.1328\n",
      "Epoch 202/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12658.1165 - mean_absolute_error: 12658.1152 - val_loss: 17933.5422 - val_mean_absolute_error: 17933.5410\n",
      "Epoch 203/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12680.4948 - mean_absolute_error: 12680.4961 - val_loss: 18014.8648 - val_mean_absolute_error: 18014.8652\n",
      "Epoch 204/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12654.8603 - mean_absolute_error: 12654.8594 - val_loss: 17910.6871 - val_mean_absolute_error: 17910.6875\n",
      "Epoch 205/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12690.2515 - mean_absolute_error: 12690.2510 - val_loss: 17958.9560 - val_mean_absolute_error: 17958.9551\n",
      "Epoch 206/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12667.9600 - mean_absolute_error: 12667.9609 - val_loss: 17921.9862 - val_mean_absolute_error: 17921.9863\n",
      "Epoch 207/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12641.5752 - mean_absolute_error: 12641.5742 - val_loss: 17945.5837 - val_mean_absolute_error: 17945.5840\n",
      "Epoch 208/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 12647.4867 - mean_absolute_error: 12647.4854 - val_loss: 17936.0973 - val_mean_absolute_error: 17936.0977\n",
      "Epoch 209/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12674.6426 - mean_absolute_error: 12674.6426 - val_loss: 17937.4713 - val_mean_absolute_error: 17937.4727\n",
      "Epoch 210/500\n",
      "1168/1168 [==============================] - 0s 75us/step - loss: 12674.5978 - mean_absolute_error: 12674.5957 - val_loss: 17970.9348 - val_mean_absolute_error: 17970.9375\n",
      "Epoch 211/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12624.3534 - mean_absolute_error: 12624.3516 - val_loss: 17927.6462 - val_mean_absolute_error: 17927.6465\n",
      "Epoch 212/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12644.1779 - mean_absolute_error: 12644.1777 - val_loss: 17958.7934 - val_mean_absolute_error: 17958.7930\n",
      "Epoch 213/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12601.6637 - mean_absolute_error: 12601.6641 - val_loss: 17990.3120 - val_mean_absolute_error: 17990.3125\n",
      "Epoch 214/500\n",
      "1168/1168 [==============================] - 0s 76us/step - loss: 12611.4621 - mean_absolute_error: 12611.4619 - val_loss: 17941.3043 - val_mean_absolute_error: 17941.3027\n",
      "Epoch 215/500\n",
      "1168/1168 [==============================] - 0s 78us/step - loss: 12630.7361 - mean_absolute_error: 12630.7354 - val_loss: 18029.1856 - val_mean_absolute_error: 18029.1855\n",
      "Epoch 216/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12694.4166 - mean_absolute_error: 12694.4160 - val_loss: 18071.4951 - val_mean_absolute_error: 18071.4961\n",
      "Epoch 217/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12599.2622 - mean_absolute_error: 12599.2617 - val_loss: 17956.5780 - val_mean_absolute_error: 17956.5762\n",
      "Epoch 218/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12657.8822 - mean_absolute_error: 12657.8809 - val_loss: 18018.6916 - val_mean_absolute_error: 18018.6914\n",
      "Epoch 219/500\n",
      "1168/1168 [==============================] - 0s 74us/step - loss: 12607.8303 - mean_absolute_error: 12607.8301 - val_loss: 17929.1231 - val_mean_absolute_error: 17929.1211\n",
      "Epoch 220/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 76us/step - loss: 12618.7735 - mean_absolute_error: 12618.7744 - val_loss: 17988.8240 - val_mean_absolute_error: 17988.8242\n",
      "Epoch 221/500\n",
      "1168/1168 [==============================] - 0s 74us/step - loss: 12600.0256 - mean_absolute_error: 12600.0264 - val_loss: 18013.3686 - val_mean_absolute_error: 18013.3691\n",
      "Epoch 222/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12594.9159 - mean_absolute_error: 12594.9141 - val_loss: 17972.5842 - val_mean_absolute_error: 17972.5840\n",
      "Epoch 223/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12581.1270 - mean_absolute_error: 12581.1270 - val_loss: 17978.8766 - val_mean_absolute_error: 17978.8750\n",
      "Epoch 224/500\n",
      "1168/1168 [==============================] - 0s 79us/step - loss: 12568.9384 - mean_absolute_error: 12568.9395 - val_loss: 17992.2000 - val_mean_absolute_error: 17992.2012\n",
      "Epoch 225/500\n",
      "1168/1168 [==============================] - 0s 101us/step - loss: 12713.5871 - mean_absolute_error: 12713.5869 - val_loss: 18020.6112 - val_mean_absolute_error: 18020.6113\n",
      "Epoch 226/500\n",
      "1168/1168 [==============================] - 0s 80us/step - loss: 12608.6624 - mean_absolute_error: 12608.6631 - val_loss: 17989.5010 - val_mean_absolute_error: 17989.5020\n",
      "Epoch 227/500\n",
      "1168/1168 [==============================] - 0s 79us/step - loss: 12663.0746 - mean_absolute_error: 12663.0732 - val_loss: 18081.8494 - val_mean_absolute_error: 18081.8516\n",
      "Epoch 228/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12579.4624 - mean_absolute_error: 12579.4619 - val_loss: 17976.5590 - val_mean_absolute_error: 17976.5586\n",
      "Epoch 229/500\n",
      "1168/1168 [==============================] - 0s 93us/step - loss: 12578.4833 - mean_absolute_error: 12578.4824 - val_loss: 18083.0495 - val_mean_absolute_error: 18083.0488\n",
      "Epoch 230/500\n",
      "1168/1168 [==============================] - 0s 82us/step - loss: 12617.9864 - mean_absolute_error: 12617.9873 - val_loss: 17964.1791 - val_mean_absolute_error: 17964.1777\n",
      "Epoch 231/500\n",
      "1168/1168 [==============================] - 0s 75us/step - loss: 12605.9703 - mean_absolute_error: 12605.9697 - val_loss: 17972.7733 - val_mean_absolute_error: 17972.7734\n",
      "Epoch 232/500\n",
      "1168/1168 [==============================] - 0s 75us/step - loss: 12617.8070 - mean_absolute_error: 12617.8076 - val_loss: 17972.7854 - val_mean_absolute_error: 17972.7852\n",
      "Epoch 233/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12568.5724 - mean_absolute_error: 12568.5713 - val_loss: 17937.9135 - val_mean_absolute_error: 17937.9141\n",
      "Epoch 234/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12613.5288 - mean_absolute_error: 12613.5264 - val_loss: 17952.7667 - val_mean_absolute_error: 17952.7676\n",
      "Epoch 235/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 12588.7869 - mean_absolute_error: 12588.7881 - val_loss: 18036.2730 - val_mean_absolute_error: 18036.2715\n",
      "Epoch 236/500\n",
      "1168/1168 [==============================] - 0s 82us/step - loss: 12590.7925 - mean_absolute_error: 12590.7930 - val_loss: 17948.0536 - val_mean_absolute_error: 17948.0547\n",
      "Epoch 237/500\n",
      "1168/1168 [==============================] - 0s 82us/step - loss: 12638.8568 - mean_absolute_error: 12638.8584 - val_loss: 18013.7808 - val_mean_absolute_error: 18013.7812\n",
      "Epoch 238/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12537.9137 - mean_absolute_error: 12537.9131 - val_loss: 17928.4629 - val_mean_absolute_error: 17928.4629\n",
      "Epoch 239/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12554.1710 - mean_absolute_error: 12554.1719 - val_loss: 17966.2133 - val_mean_absolute_error: 17966.2148\n",
      "Epoch 240/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12569.9508 - mean_absolute_error: 12569.9502 - val_loss: 18028.8167 - val_mean_absolute_error: 18028.8164\n",
      "Epoch 241/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 12573.6037 - mean_absolute_error: 12573.6035 - val_loss: 17932.1977 - val_mean_absolute_error: 17932.1992\n",
      "Epoch 242/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12573.4847 - mean_absolute_error: 12573.4854 - val_loss: 18001.3780 - val_mean_absolute_error: 18001.3789\n",
      "Epoch 243/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12554.7915 - mean_absolute_error: 12554.7949 - val_loss: 17959.7299 - val_mean_absolute_error: 17959.7305\n",
      "Epoch 244/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 12569.7686 - mean_absolute_error: 12569.7686 - val_loss: 17948.4149 - val_mean_absolute_error: 17948.4141\n",
      "Epoch 245/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 12540.9142 - mean_absolute_error: 12540.9121 - val_loss: 18095.3341 - val_mean_absolute_error: 18095.3340\n",
      "Epoch 246/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12591.9403 - mean_absolute_error: 12591.9414 - val_loss: 17918.8397 - val_mean_absolute_error: 17918.8398\n",
      "Epoch 247/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 12537.0494 - mean_absolute_error: 12537.0508 - val_loss: 17979.1516 - val_mean_absolute_error: 17979.1523\n",
      "Epoch 248/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 12525.8201 - mean_absolute_error: 12525.8213 - val_loss: 17962.2474 - val_mean_absolute_error: 17962.2500\n",
      "Epoch 249/500\n",
      "1168/1168 [==============================] - 0s 78us/step - loss: 12514.6729 - mean_absolute_error: 12514.6729 - val_loss: 18035.8931 - val_mean_absolute_error: 18035.8945\n",
      "Epoch 250/500\n",
      "1168/1168 [==============================] - 0s 76us/step - loss: 12526.6985 - mean_absolute_error: 12526.7002 - val_loss: 17969.3995 - val_mean_absolute_error: 17969.3984\n",
      "Epoch 251/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12515.6647 - mean_absolute_error: 12515.6631 - val_loss: 17930.7129 - val_mean_absolute_error: 17930.7109\n",
      "Epoch 252/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12635.0939 - mean_absolute_error: 12635.0928 - val_loss: 18097.6322 - val_mean_absolute_error: 18097.6328\n",
      "Epoch 253/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 12514.8922 - mean_absolute_error: 12514.8926 - val_loss: 17968.2089 - val_mean_absolute_error: 17968.2090\n",
      "Epoch 254/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 12521.3625 - mean_absolute_error: 12521.3623 - val_loss: 17955.9933 - val_mean_absolute_error: 17955.9922\n",
      "Epoch 255/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12513.7082 - mean_absolute_error: 12513.7061 - val_loss: 18032.6074 - val_mean_absolute_error: 18032.6094\n",
      "Epoch 256/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 12510.4056 - mean_absolute_error: 12510.4033 - val_loss: 18056.9577 - val_mean_absolute_error: 18056.9570\n",
      "Epoch 257/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12566.6766 - mean_absolute_error: 12566.6768 - val_loss: 17982.4559 - val_mean_absolute_error: 17982.4570\n",
      "Epoch 258/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 12564.7260 - mean_absolute_error: 12564.7256 - val_loss: 18092.4400 - val_mean_absolute_error: 18092.4414\n",
      "Epoch 259/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12514.3273 - mean_absolute_error: 12514.3281 - val_loss: 18008.6670 - val_mean_absolute_error: 18008.6660\n",
      "Epoch 260/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12510.6031 - mean_absolute_error: 12510.6035 - val_loss: 17979.0023 - val_mean_absolute_error: 17979.0020\n",
      "Epoch 261/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 12505.4166 - mean_absolute_error: 12505.4170 - val_loss: 17998.6989 - val_mean_absolute_error: 17998.6992\n",
      "Epoch 262/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12535.4274 - mean_absolute_error: 12535.4268 - val_loss: 17985.2660 - val_mean_absolute_error: 17985.2656\n",
      "Epoch 263/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12523.7250 - mean_absolute_error: 12523.7266 - val_loss: 17978.4407 - val_mean_absolute_error: 17978.4395\n",
      "Epoch 264/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 68us/step - loss: 12496.2032 - mean_absolute_error: 12496.2041 - val_loss: 17968.5457 - val_mean_absolute_error: 17968.5449\n",
      "Epoch 265/500\n",
      "1168/1168 [==============================] - 0s 77us/step - loss: 12498.2244 - mean_absolute_error: 12498.2256 - val_loss: 17951.9036 - val_mean_absolute_error: 17951.9043\n",
      "Epoch 266/500\n",
      "1168/1168 [==============================] - 0s 79us/step - loss: 12488.5129 - mean_absolute_error: 12488.5146 - val_loss: 18021.2986 - val_mean_absolute_error: 18021.2988\n",
      "Epoch 267/500\n",
      "1168/1168 [==============================] - 0s 76us/step - loss: 12494.5171 - mean_absolute_error: 12494.5176 - val_loss: 18070.9886 - val_mean_absolute_error: 18070.9883\n",
      "Epoch 268/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12499.1775 - mean_absolute_error: 12499.1777 - val_loss: 18080.4348 - val_mean_absolute_error: 18080.4375\n",
      "Epoch 269/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 12509.2914 - mean_absolute_error: 12509.2920 - val_loss: 17984.3975 - val_mean_absolute_error: 17984.3984\n",
      "Epoch 270/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 12526.6972 - mean_absolute_error: 12526.6982 - val_loss: 18128.8530 - val_mean_absolute_error: 18128.8535\n",
      "Epoch 271/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12521.8057 - mean_absolute_error: 12521.8066 - val_loss: 17976.2730 - val_mean_absolute_error: 17976.2734\n",
      "Epoch 272/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 12496.6182 - mean_absolute_error: 12496.6191 - val_loss: 18088.7597 - val_mean_absolute_error: 18088.7598\n",
      "Epoch 273/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 12496.0066 - mean_absolute_error: 12496.0049 - val_loss: 18008.6012 - val_mean_absolute_error: 18008.6016\n",
      "Epoch 274/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 12533.6009 - mean_absolute_error: 12533.6025 - val_loss: 17999.8752 - val_mean_absolute_error: 17999.8770\n",
      "Epoch 275/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 12481.4303 - mean_absolute_error: 12481.4307 - val_loss: 17986.5557 - val_mean_absolute_error: 17986.5547\n",
      "Epoch 276/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 12493.1316 - mean_absolute_error: 12493.1309 - val_loss: 17988.1769 - val_mean_absolute_error: 17988.1777\n",
      "Epoch 277/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12449.3016 - mean_absolute_error: 12449.3027 - val_loss: 17965.4277 - val_mean_absolute_error: 17965.4277\n",
      "Epoch 278/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 12452.4578 - mean_absolute_error: 12452.4609 - val_loss: 18033.7053 - val_mean_absolute_error: 18033.7051\n",
      "Epoch 279/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12453.6017 - mean_absolute_error: 12453.6016 - val_loss: 18067.7065 - val_mean_absolute_error: 18067.7070\n",
      "Epoch 280/500\n",
      "1168/1168 [==============================] - 0s 75us/step - loss: 12534.3653 - mean_absolute_error: 12534.3643 - val_loss: 17978.1914 - val_mean_absolute_error: 17978.1914\n",
      "Epoch 281/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12474.1524 - mean_absolute_error: 12474.1514 - val_loss: 18017.6331 - val_mean_absolute_error: 18017.6328\n",
      "Epoch 282/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 12472.0066 - mean_absolute_error: 12472.0068 - val_loss: 17949.7850 - val_mean_absolute_error: 17949.7852\n",
      "Epoch 283/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12467.6099 - mean_absolute_error: 12467.6104 - val_loss: 18045.9394 - val_mean_absolute_error: 18045.9395\n",
      "Epoch 284/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12495.1364 - mean_absolute_error: 12495.1357 - val_loss: 17983.4167 - val_mean_absolute_error: 17983.4141\n",
      "Epoch 285/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12429.8118 - mean_absolute_error: 12429.8125 - val_loss: 17960.1143 - val_mean_absolute_error: 17960.1172\n",
      "Epoch 286/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12431.3839 - mean_absolute_error: 12431.3828 - val_loss: 17952.3392 - val_mean_absolute_error: 17952.3398\n",
      "Epoch 287/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12416.2843 - mean_absolute_error: 12416.2842 - val_loss: 18004.0505 - val_mean_absolute_error: 18004.0508\n",
      "Epoch 288/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12431.2269 - mean_absolute_error: 12431.2275 - val_loss: 18005.9246 - val_mean_absolute_error: 18005.9238\n",
      "Epoch 289/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12410.3512 - mean_absolute_error: 12410.3506 - val_loss: 17935.9388 - val_mean_absolute_error: 17935.9395\n",
      "Epoch 290/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12416.8560 - mean_absolute_error: 12416.8564 - val_loss: 17938.1470 - val_mean_absolute_error: 17938.1465\n",
      "Epoch 291/500\n",
      "1168/1168 [==============================] - 0s 77us/step - loss: 12438.8174 - mean_absolute_error: 12438.8164 - val_loss: 17952.5812 - val_mean_absolute_error: 17952.5801\n",
      "Epoch 292/500\n",
      "1168/1168 [==============================] - 0s 89us/step - loss: 12429.4538 - mean_absolute_error: 12429.4541 - val_loss: 18004.0871 - val_mean_absolute_error: 18004.0879\n",
      "Epoch 293/500\n",
      "1168/1168 [==============================] - 0s 79us/step - loss: 12411.4254 - mean_absolute_error: 12411.4258 - val_loss: 17991.0245 - val_mean_absolute_error: 17991.0215\n",
      "Epoch 294/500\n",
      "1168/1168 [==============================] - 0s 85us/step - loss: 12405.0427 - mean_absolute_error: 12405.0420 - val_loss: 17922.4617 - val_mean_absolute_error: 17922.4609\n",
      "Epoch 295/500\n",
      "1168/1168 [==============================] - 0s 87us/step - loss: 12421.4359 - mean_absolute_error: 12421.4355 - val_loss: 18041.3477 - val_mean_absolute_error: 18041.3496\n",
      "Epoch 296/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12390.9999 - mean_absolute_error: 12390.9990 - val_loss: 17949.5640 - val_mean_absolute_error: 17949.5625\n",
      "Epoch 297/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12409.7857 - mean_absolute_error: 12409.7842 - val_loss: 17942.9406 - val_mean_absolute_error: 17942.9395\n",
      "Epoch 298/500\n",
      "1168/1168 [==============================] - 0s 77us/step - loss: 12417.7558 - mean_absolute_error: 12417.7559 - val_loss: 17980.4950 - val_mean_absolute_error: 17980.4941\n",
      "Epoch 299/500\n",
      "1168/1168 [==============================] - 0s 90us/step - loss: 12356.3559 - mean_absolute_error: 12356.3564 - val_loss: 18020.6794 - val_mean_absolute_error: 18020.6797\n",
      "Epoch 300/500\n",
      "1168/1168 [==============================] - 0s 84us/step - loss: 12412.6645 - mean_absolute_error: 12412.6631 - val_loss: 17990.9539 - val_mean_absolute_error: 17990.9512\n",
      "Epoch 301/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12368.4453 - mean_absolute_error: 12368.4443 - val_loss: 17979.9796 - val_mean_absolute_error: 17979.9805\n",
      "Epoch 302/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12403.4048 - mean_absolute_error: 12403.4062 - val_loss: 17969.8938 - val_mean_absolute_error: 17969.8945\n",
      "Epoch 303/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12398.1506 - mean_absolute_error: 12398.1514 - val_loss: 18045.3643 - val_mean_absolute_error: 18045.3652\n",
      "Epoch 304/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12371.9786 - mean_absolute_error: 12371.9785 - val_loss: 18032.1117 - val_mean_absolute_error: 18032.1113\n",
      "Epoch 305/500\n",
      "1168/1168 [==============================] - 0s 79us/step - loss: 12357.5418 - mean_absolute_error: 12357.5430 - val_loss: 18017.5267 - val_mean_absolute_error: 18017.5273\n",
      "Epoch 306/500\n",
      "1168/1168 [==============================] - 0s 76us/step - loss: 12354.7161 - mean_absolute_error: 12354.7178 - val_loss: 17956.2837 - val_mean_absolute_error: 17956.2812\n",
      "Epoch 307/500\n",
      "1168/1168 [==============================] - 0s 75us/step - loss: 12372.9773 - mean_absolute_error: 12372.9766 - val_loss: 17967.6354 - val_mean_absolute_error: 17967.6348\n",
      "Epoch 308/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 70us/step - loss: 12352.3391 - mean_absolute_error: 12352.3389 - val_loss: 17986.0569 - val_mean_absolute_error: 17986.0566\n",
      "Epoch 309/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12341.3684 - mean_absolute_error: 12341.3682 - val_loss: 17984.2054 - val_mean_absolute_error: 17984.2051\n",
      "Epoch 310/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12332.5593 - mean_absolute_error: 12332.5576 - val_loss: 18008.6102 - val_mean_absolute_error: 18008.6113\n",
      "Epoch 311/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12343.6882 - mean_absolute_error: 12343.6885 - val_loss: 17998.7063 - val_mean_absolute_error: 17998.7070\n",
      "Epoch 312/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12323.6890 - mean_absolute_error: 12323.6904 - val_loss: 17991.1552 - val_mean_absolute_error: 17991.1543\n",
      "Epoch 313/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12324.4859 - mean_absolute_error: 12324.4863 - val_loss: 17988.3448 - val_mean_absolute_error: 17988.3438\n",
      "Epoch 314/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12316.3268 - mean_absolute_error: 12316.3262 - val_loss: 17983.0679 - val_mean_absolute_error: 17983.0684\n",
      "Epoch 315/500\n",
      "1168/1168 [==============================] - 0s 75us/step - loss: 12355.1463 - mean_absolute_error: 12355.1445 - val_loss: 17895.2253 - val_mean_absolute_error: 17895.2246\n",
      "Epoch 316/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12364.9197 - mean_absolute_error: 12364.9199 - val_loss: 18041.5420 - val_mean_absolute_error: 18041.5410\n",
      "Epoch 317/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12325.0421 - mean_absolute_error: 12325.0420 - val_loss: 17908.5200 - val_mean_absolute_error: 17908.5195\n",
      "Epoch 318/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12319.1025 - mean_absolute_error: 12319.1025 - val_loss: 17964.3495 - val_mean_absolute_error: 17964.3496\n",
      "Epoch 319/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12359.6594 - mean_absolute_error: 12359.6602 - val_loss: 17935.1305 - val_mean_absolute_error: 17935.1309\n",
      "Epoch 320/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12342.2741 - mean_absolute_error: 12342.2744 - val_loss: 17957.4688 - val_mean_absolute_error: 17957.4688\n",
      "Epoch 321/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12299.9971 - mean_absolute_error: 12299.9980 - val_loss: 17925.9544 - val_mean_absolute_error: 17925.9531\n",
      "Epoch 322/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12269.0574 - mean_absolute_error: 12269.0557 - val_loss: 18042.8488 - val_mean_absolute_error: 18042.8496\n",
      "Epoch 323/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12320.9024 - mean_absolute_error: 12320.9033 - val_loss: 17901.3183 - val_mean_absolute_error: 17901.3203\n",
      "Epoch 324/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12376.9315 - mean_absolute_error: 12376.9307 - val_loss: 18096.0949 - val_mean_absolute_error: 18096.0938\n",
      "Epoch 325/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12288.3473 - mean_absolute_error: 12288.3486 - val_loss: 17984.8422 - val_mean_absolute_error: 17984.8438\n",
      "Epoch 326/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12300.3917 - mean_absolute_error: 12300.3926 - val_loss: 18002.3865 - val_mean_absolute_error: 18002.3867\n",
      "Epoch 327/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12332.6128 - mean_absolute_error: 12332.6123 - val_loss: 17890.0461 - val_mean_absolute_error: 17890.0469\n",
      "Epoch 328/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12307.4099 - mean_absolute_error: 12307.4111 - val_loss: 17933.5692 - val_mean_absolute_error: 17933.5684\n",
      "Epoch 329/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 12272.4227 - mean_absolute_error: 12272.4229 - val_loss: 17911.1224 - val_mean_absolute_error: 17911.1211\n",
      "Epoch 330/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 12259.1353 - mean_absolute_error: 12259.1357 - val_loss: 17960.9242 - val_mean_absolute_error: 17960.9238\n",
      "Epoch 331/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12315.1019 - mean_absolute_error: 12315.1025 - val_loss: 17880.9747 - val_mean_absolute_error: 17880.9746\n",
      "Epoch 332/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12229.2892 - mean_absolute_error: 12229.2881 - val_loss: 17945.3767 - val_mean_absolute_error: 17945.3770\n",
      "Epoch 333/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12253.1445 - mean_absolute_error: 12253.1445 - val_loss: 17868.6769 - val_mean_absolute_error: 17868.6777\n",
      "Epoch 334/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12241.9695 - mean_absolute_error: 12241.9707 - val_loss: 17896.1592 - val_mean_absolute_error: 17896.1602\n",
      "Epoch 335/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12254.4164 - mean_absolute_error: 12254.4170 - val_loss: 17884.7864 - val_mean_absolute_error: 17884.7871\n",
      "Epoch 336/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 12223.2758 - mean_absolute_error: 12223.2744 - val_loss: 17867.6131 - val_mean_absolute_error: 17867.6152\n",
      "Epoch 337/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 12289.5478 - mean_absolute_error: 12289.5508 - val_loss: 17920.1907 - val_mean_absolute_error: 17920.1895\n",
      "Epoch 338/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 12271.5832 - mean_absolute_error: 12271.5820 - val_loss: 17892.3408 - val_mean_absolute_error: 17892.3398\n",
      "Epoch 339/500\n",
      "1168/1168 [==============================] - 0s 76us/step - loss: 12219.2748 - mean_absolute_error: 12219.2744 - val_loss: 17879.1853 - val_mean_absolute_error: 17879.1875\n",
      "Epoch 340/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12231.6568 - mean_absolute_error: 12231.6562 - val_loss: 17876.1686 - val_mean_absolute_error: 17876.1699\n",
      "Epoch 341/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12242.3302 - mean_absolute_error: 12242.3301 - val_loss: 17875.9373 - val_mean_absolute_error: 17875.9375\n",
      "Epoch 342/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12209.6544 - mean_absolute_error: 12209.6543 - val_loss: 17902.1745 - val_mean_absolute_error: 17902.1738\n",
      "Epoch 343/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 12230.8887 - mean_absolute_error: 12230.8887 - val_loss: 17955.4173 - val_mean_absolute_error: 17955.4180\n",
      "Epoch 344/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12226.7672 - mean_absolute_error: 12226.7676 - val_loss: 17884.1236 - val_mean_absolute_error: 17884.1230\n",
      "Epoch 345/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12182.4176 - mean_absolute_error: 12182.4170 - val_loss: 17897.0251 - val_mean_absolute_error: 17897.0254\n",
      "Epoch 346/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12189.2014 - mean_absolute_error: 12189.2012 - val_loss: 17899.5006 - val_mean_absolute_error: 17899.5000\n",
      "Epoch 347/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12224.3846 - mean_absolute_error: 12224.3828 - val_loss: 17922.8014 - val_mean_absolute_error: 17922.8008\n",
      "Epoch 348/500\n",
      "1168/1168 [==============================] - 0s 75us/step - loss: 12198.6249 - mean_absolute_error: 12198.6240 - val_loss: 17863.2346 - val_mean_absolute_error: 17863.2344\n",
      "Epoch 349/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12175.1662 - mean_absolute_error: 12175.1650 - val_loss: 17916.3947 - val_mean_absolute_error: 17916.3945\n",
      "Epoch 350/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12208.4247 - mean_absolute_error: 12208.4258 - val_loss: 17899.8657 - val_mean_absolute_error: 17899.8652\n",
      "Epoch 351/500\n",
      "1168/1168 [==============================] - 0s 74us/step - loss: 12230.9809 - mean_absolute_error: 12230.9795 - val_loss: 17867.2251 - val_mean_absolute_error: 17867.2266\n",
      "Epoch 352/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 71us/step - loss: 12174.6088 - mean_absolute_error: 12174.6084 - val_loss: 17850.0784 - val_mean_absolute_error: 17850.0801\n",
      "Epoch 353/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12304.2209 - mean_absolute_error: 12304.2197 - val_loss: 17847.8940 - val_mean_absolute_error: 17847.8945\n",
      "Epoch 354/500\n",
      "1168/1168 [==============================] - 0s 82us/step - loss: 12214.9984 - mean_absolute_error: 12214.9961 - val_loss: 17898.3439 - val_mean_absolute_error: 17898.3418\n",
      "Epoch 355/500\n",
      "1168/1168 [==============================] - 0s 80us/step - loss: 12184.3467 - mean_absolute_error: 12184.3486 - val_loss: 17842.9601 - val_mean_absolute_error: 17842.9609\n",
      "Epoch 356/500\n",
      "1168/1168 [==============================] - 0s 76us/step - loss: 12195.5473 - mean_absolute_error: 12195.5479 - val_loss: 17853.8488 - val_mean_absolute_error: 17853.8477\n",
      "Epoch 357/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12190.6702 - mean_absolute_error: 12190.6709 - val_loss: 17865.7697 - val_mean_absolute_error: 17865.7695\n",
      "Epoch 358/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12149.4453 - mean_absolute_error: 12149.4453 - val_loss: 17850.8584 - val_mean_absolute_error: 17850.8574\n",
      "Epoch 359/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12135.7103 - mean_absolute_error: 12135.7109 - val_loss: 17948.4382 - val_mean_absolute_error: 17948.4375\n",
      "Epoch 360/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12143.6226 - mean_absolute_error: 12143.6230 - val_loss: 17963.4845 - val_mean_absolute_error: 17963.4844\n",
      "Epoch 361/500\n",
      "1168/1168 [==============================] - 0s 74us/step - loss: 12134.0973 - mean_absolute_error: 12134.0967 - val_loss: 17859.7109 - val_mean_absolute_error: 17859.7109\n",
      "Epoch 362/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12142.5366 - mean_absolute_error: 12142.5371 - val_loss: 17856.0591 - val_mean_absolute_error: 17856.0605\n",
      "Epoch 363/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12103.9991 - mean_absolute_error: 12103.9980 - val_loss: 17849.1624 - val_mean_absolute_error: 17849.1602\n",
      "Epoch 364/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12114.7093 - mean_absolute_error: 12114.7100 - val_loss: 17870.1583 - val_mean_absolute_error: 17870.1582\n",
      "Epoch 365/500\n",
      "1168/1168 [==============================] - 0s 77us/step - loss: 12112.5099 - mean_absolute_error: 12112.5117 - val_loss: 17895.6231 - val_mean_absolute_error: 17895.6230\n",
      "Epoch 366/500\n",
      "1168/1168 [==============================] - 0s 80us/step - loss: 12100.5070 - mean_absolute_error: 12100.5068 - val_loss: 17864.5641 - val_mean_absolute_error: 17864.5645\n",
      "Epoch 367/500\n",
      "1168/1168 [==============================] - 0s 74us/step - loss: 12078.0350 - mean_absolute_error: 12078.0381 - val_loss: 17802.1922 - val_mean_absolute_error: 17802.1914\n",
      "Epoch 368/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 12137.4160 - mean_absolute_error: 12137.4160 - val_loss: 17867.1979 - val_mean_absolute_error: 17867.1973\n",
      "Epoch 369/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12129.9999 - mean_absolute_error: 12130.0020 - val_loss: 17837.3538 - val_mean_absolute_error: 17837.3535\n",
      "Epoch 370/500\n",
      "1168/1168 [==============================] - 0s 75us/step - loss: 12095.5398 - mean_absolute_error: 12095.5391 - val_loss: 17817.9317 - val_mean_absolute_error: 17817.9316\n",
      "Epoch 371/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12085.2722 - mean_absolute_error: 12085.2734 - val_loss: 17879.9911 - val_mean_absolute_error: 17879.9922\n",
      "Epoch 372/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12068.7882 - mean_absolute_error: 12068.7881 - val_loss: 17800.1111 - val_mean_absolute_error: 17800.1113\n",
      "Epoch 373/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12050.1981 - mean_absolute_error: 12050.1973 - val_loss: 17808.9351 - val_mean_absolute_error: 17808.9375\n",
      "Epoch 374/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12108.9670 - mean_absolute_error: 12108.9668 - val_loss: 17800.6047 - val_mean_absolute_error: 17800.6055\n",
      "Epoch 375/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12091.5291 - mean_absolute_error: 12091.5303 - val_loss: 17824.4719 - val_mean_absolute_error: 17824.4727\n",
      "Epoch 376/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12059.0248 - mean_absolute_error: 12059.0264 - val_loss: 17797.4315 - val_mean_absolute_error: 17797.4316\n",
      "Epoch 377/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 12050.5432 - mean_absolute_error: 12050.5430 - val_loss: 17839.2185 - val_mean_absolute_error: 17839.2148\n",
      "Epoch 378/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12037.9027 - mean_absolute_error: 12037.9033 - val_loss: 17785.6516 - val_mean_absolute_error: 17785.6504\n",
      "Epoch 379/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 12047.4205 - mean_absolute_error: 12047.4209 - val_loss: 17875.7013 - val_mean_absolute_error: 17875.7012\n",
      "Epoch 380/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12026.2113 - mean_absolute_error: 12026.2119 - val_loss: 17805.1672 - val_mean_absolute_error: 17805.1699\n",
      "Epoch 381/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12032.3815 - mean_absolute_error: 12032.3809 - val_loss: 17813.1754 - val_mean_absolute_error: 17813.1758\n",
      "Epoch 382/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12015.4953 - mean_absolute_error: 12015.4951 - val_loss: 17775.1208 - val_mean_absolute_error: 17775.1191\n",
      "Epoch 383/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12019.4230 - mean_absolute_error: 12019.4248 - val_loss: 17807.4362 - val_mean_absolute_error: 17807.4355\n",
      "Epoch 384/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12033.2948 - mean_absolute_error: 12033.2920 - val_loss: 17787.1287 - val_mean_absolute_error: 17787.1289\n",
      "Epoch 385/500\n",
      "1168/1168 [==============================] - 0s 74us/step - loss: 12023.8215 - mean_absolute_error: 12023.8223 - val_loss: 17764.7737 - val_mean_absolute_error: 17764.7715\n",
      "Epoch 386/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12058.1415 - mean_absolute_error: 12058.1426 - val_loss: 17786.8481 - val_mean_absolute_error: 17786.8477\n",
      "Epoch 387/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 12088.4586 - mean_absolute_error: 12088.4609 - val_loss: 17791.9112 - val_mean_absolute_error: 17791.9102\n",
      "Epoch 388/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12008.0172 - mean_absolute_error: 12008.0176 - val_loss: 17791.9179 - val_mean_absolute_error: 17791.9199\n",
      "Epoch 389/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 11995.5962 - mean_absolute_error: 11995.5957 - val_loss: 17768.3943 - val_mean_absolute_error: 17768.3965\n",
      "Epoch 390/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11992.0738 - mean_absolute_error: 11992.0742 - val_loss: 17807.3632 - val_mean_absolute_error: 17807.3633\n",
      "Epoch 391/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 11991.8100 - mean_absolute_error: 11991.8086 - val_loss: 17795.5517 - val_mean_absolute_error: 17795.5508\n",
      "Epoch 392/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 11973.3858 - mean_absolute_error: 11973.3848 - val_loss: 17771.8452 - val_mean_absolute_error: 17771.8438\n",
      "Epoch 393/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 11981.2662 - mean_absolute_error: 11981.2646 - val_loss: 17753.3087 - val_mean_absolute_error: 17753.3105\n",
      "Epoch 394/500\n",
      "1168/1168 [==============================] - 0s 74us/step - loss: 11954.9029 - mean_absolute_error: 11954.9033 - val_loss: 17775.4420 - val_mean_absolute_error: 17775.4414\n",
      "Epoch 395/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 11950.4540 - mean_absolute_error: 11950.4551 - val_loss: 17820.1600 - val_mean_absolute_error: 17820.1602\n",
      "Epoch 396/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 79us/step - loss: 11995.9460 - mean_absolute_error: 11995.9463 - val_loss: 17818.1041 - val_mean_absolute_error: 17818.1035\n",
      "Epoch 397/500\n",
      "1168/1168 [==============================] - 0s 77us/step - loss: 12012.6442 - mean_absolute_error: 12012.6445 - val_loss: 17861.1290 - val_mean_absolute_error: 17861.1270\n",
      "Epoch 398/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 11986.8273 - mean_absolute_error: 11986.8271 - val_loss: 17754.7408 - val_mean_absolute_error: 17754.7422\n",
      "Epoch 399/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 11978.6934 - mean_absolute_error: 11978.6943 - val_loss: 17759.6787 - val_mean_absolute_error: 17759.6777\n",
      "Epoch 400/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11946.5019 - mean_absolute_error: 11946.5039 - val_loss: 17712.8052 - val_mean_absolute_error: 17712.8047\n",
      "Epoch 401/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11923.1248 - mean_absolute_error: 11923.1240 - val_loss: 17730.9108 - val_mean_absolute_error: 17730.9102\n",
      "Epoch 402/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11938.3916 - mean_absolute_error: 11938.3926 - val_loss: 17738.0118 - val_mean_absolute_error: 17738.0098\n",
      "Epoch 403/500\n",
      "1168/1168 [==============================] - 0s 81us/step - loss: 11927.8883 - mean_absolute_error: 11927.8896 - val_loss: 17828.6156 - val_mean_absolute_error: 17828.6172\n",
      "Epoch 404/500\n",
      "1168/1168 [==============================] - 0s 83us/step - loss: 11972.1861 - mean_absolute_error: 11972.1836 - val_loss: 17742.3305 - val_mean_absolute_error: 17742.3301\n",
      "Epoch 405/500\n",
      "1168/1168 [==============================] - 0s 79us/step - loss: 11919.0923 - mean_absolute_error: 11919.0918 - val_loss: 17697.5353 - val_mean_absolute_error: 17697.5352\n",
      "Epoch 406/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 11921.8120 - mean_absolute_error: 11921.8125 - val_loss: 17695.0985 - val_mean_absolute_error: 17695.0977\n",
      "Epoch 407/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11987.1783 - mean_absolute_error: 11987.1777 - val_loss: 17810.5126 - val_mean_absolute_error: 17810.5117\n",
      "Epoch 408/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11940.4460 - mean_absolute_error: 11940.4434 - val_loss: 17734.3330 - val_mean_absolute_error: 17734.3359\n",
      "Epoch 409/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11900.0425 - mean_absolute_error: 11900.0420 - val_loss: 17726.6545 - val_mean_absolute_error: 17726.6543\n",
      "Epoch 410/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 11888.6831 - mean_absolute_error: 11888.6836 - val_loss: 17768.0987 - val_mean_absolute_error: 17768.0957\n",
      "Epoch 411/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 11903.1433 - mean_absolute_error: 11903.1426 - val_loss: 17726.6634 - val_mean_absolute_error: 17726.6641\n",
      "Epoch 412/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11880.1257 - mean_absolute_error: 11880.1270 - val_loss: 17738.5615 - val_mean_absolute_error: 17738.5625\n",
      "Epoch 413/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 11860.9758 - mean_absolute_error: 11860.9756 - val_loss: 17738.0117 - val_mean_absolute_error: 17738.0098\n",
      "Epoch 414/500\n",
      "1168/1168 [==============================] - 0s 80us/step - loss: 11915.2552 - mean_absolute_error: 11915.2549 - val_loss: 17718.7054 - val_mean_absolute_error: 17718.7051\n",
      "Epoch 415/500\n",
      "1168/1168 [==============================] - 0s 84us/step - loss: 11859.7399 - mean_absolute_error: 11859.7402 - val_loss: 17695.8783 - val_mean_absolute_error: 17695.8789\n",
      "Epoch 416/500\n",
      "1168/1168 [==============================] - 0s 80us/step - loss: 11897.8125 - mean_absolute_error: 11897.8125 - val_loss: 17780.5912 - val_mean_absolute_error: 17780.5918\n",
      "Epoch 417/500\n",
      "1168/1168 [==============================] - 0s 80us/step - loss: 11834.7729 - mean_absolute_error: 11834.7734 - val_loss: 17791.8091 - val_mean_absolute_error: 17791.8105\n",
      "Epoch 418/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 11929.8936 - mean_absolute_error: 11929.8936 - val_loss: 17666.9688 - val_mean_absolute_error: 17666.9688\n",
      "Epoch 419/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 11863.7755 - mean_absolute_error: 11863.7754 - val_loss: 17824.1698 - val_mean_absolute_error: 17824.1699\n",
      "Epoch 420/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11894.2280 - mean_absolute_error: 11894.2266 - val_loss: 17690.7652 - val_mean_absolute_error: 17690.7656\n",
      "Epoch 421/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11883.4610 - mean_absolute_error: 11883.4609 - val_loss: 17717.7147 - val_mean_absolute_error: 17717.7148\n",
      "Epoch 422/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 11855.9314 - mean_absolute_error: 11855.9326 - val_loss: 17688.3696 - val_mean_absolute_error: 17688.3691\n",
      "Epoch 423/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 11864.3036 - mean_absolute_error: 11864.3027 - val_loss: 17697.0834 - val_mean_absolute_error: 17697.0840\n",
      "Epoch 424/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 11817.7325 - mean_absolute_error: 11817.7324 - val_loss: 17670.8224 - val_mean_absolute_error: 17670.8242\n",
      "Epoch 425/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11799.6825 - mean_absolute_error: 11799.6816 - val_loss: 17726.0659 - val_mean_absolute_error: 17726.0664\n",
      "Epoch 426/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 11851.7063 - mean_absolute_error: 11851.7051 - val_loss: 17678.2928 - val_mean_absolute_error: 17678.2930\n",
      "Epoch 427/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 11812.8873 - mean_absolute_error: 11812.8877 - val_loss: 17686.2647 - val_mean_absolute_error: 17686.2656\n",
      "Epoch 428/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 11812.9674 - mean_absolute_error: 11812.9688 - val_loss: 17763.1674 - val_mean_absolute_error: 17763.1660\n",
      "Epoch 429/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 11787.5590 - mean_absolute_error: 11787.5596 - val_loss: 17668.1130 - val_mean_absolute_error: 17668.1113\n",
      "Epoch 430/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11772.2823 - mean_absolute_error: 11772.2812 - val_loss: 17743.3500 - val_mean_absolute_error: 17743.3496\n",
      "Epoch 431/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 11785.1457 - mean_absolute_error: 11785.1465 - val_loss: 17690.9260 - val_mean_absolute_error: 17690.9258\n",
      "Epoch 432/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11781.2038 - mean_absolute_error: 11781.2031 - val_loss: 17675.2921 - val_mean_absolute_error: 17675.2910\n",
      "Epoch 433/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 11781.2990 - mean_absolute_error: 11781.2998 - val_loss: 17658.6690 - val_mean_absolute_error: 17658.6699\n",
      "Epoch 434/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 11771.8996 - mean_absolute_error: 11771.8994 - val_loss: 17656.2596 - val_mean_absolute_error: 17656.2598\n",
      "Epoch 435/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 11855.2659 - mean_absolute_error: 11855.2676 - val_loss: 17788.1205 - val_mean_absolute_error: 17788.1191\n",
      "Epoch 436/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 11840.5860 - mean_absolute_error: 11840.5869 - val_loss: 17689.4743 - val_mean_absolute_error: 17689.4746\n",
      "Epoch 437/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 11785.5312 - mean_absolute_error: 11785.5332 - val_loss: 17682.2793 - val_mean_absolute_error: 17682.2793\n",
      "Epoch 438/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11738.0378 - mean_absolute_error: 11738.0371 - val_loss: 17693.5932 - val_mean_absolute_error: 17693.5938\n",
      "Epoch 439/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 11733.4643 - mean_absolute_error: 11733.4639 - val_loss: 17753.5741 - val_mean_absolute_error: 17753.5723\n",
      "Epoch 440/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 75us/step - loss: 11753.4894 - mean_absolute_error: 11753.4873 - val_loss: 17646.1194 - val_mean_absolute_error: 17646.1172\n",
      "Epoch 441/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 11775.3260 - mean_absolute_error: 11775.3281 - val_loss: 17676.6697 - val_mean_absolute_error: 17676.6680\n",
      "Epoch 442/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 11720.5225 - mean_absolute_error: 11720.5244 - val_loss: 17743.5897 - val_mean_absolute_error: 17743.5898\n",
      "Epoch 443/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11752.1235 - mean_absolute_error: 11752.1240 - val_loss: 17621.7291 - val_mean_absolute_error: 17621.7285\n",
      "Epoch 444/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 11731.6038 - mean_absolute_error: 11731.6025 - val_loss: 17626.6334 - val_mean_absolute_error: 17626.6348\n",
      "Epoch 445/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11720.8617 - mean_absolute_error: 11720.8613 - val_loss: 17654.6760 - val_mean_absolute_error: 17654.6758\n",
      "Epoch 446/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 11756.6831 - mean_absolute_error: 11756.6816 - val_loss: 17717.9180 - val_mean_absolute_error: 17717.9180\n",
      "Epoch 447/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 11763.7400 - mean_absolute_error: 11763.7393 - val_loss: 17700.8340 - val_mean_absolute_error: 17700.8340\n",
      "Epoch 448/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11713.3224 - mean_absolute_error: 11713.3223 - val_loss: 17630.9253 - val_mean_absolute_error: 17630.9238\n",
      "Epoch 449/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 11730.0277 - mean_absolute_error: 11730.0273 - val_loss: 17638.0788 - val_mean_absolute_error: 17638.0762\n",
      "Epoch 450/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 11713.8243 - mean_absolute_error: 11713.8242 - val_loss: 17614.7917 - val_mean_absolute_error: 17614.7910\n",
      "Epoch 451/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 11805.0995 - mean_absolute_error: 11805.1006 - val_loss: 17633.6048 - val_mean_absolute_error: 17633.6035\n",
      "Epoch 452/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 11740.5204 - mean_absolute_error: 11740.5205 - val_loss: 17655.7864 - val_mean_absolute_error: 17655.7852\n",
      "Epoch 453/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 11705.2168 - mean_absolute_error: 11705.2158 - val_loss: 17608.5468 - val_mean_absolute_error: 17608.5449\n",
      "Epoch 454/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 11657.4845 - mean_absolute_error: 11657.4834 - val_loss: 17607.1895 - val_mean_absolute_error: 17607.1875\n",
      "Epoch 455/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 11673.3366 - mean_absolute_error: 11673.3359 - val_loss: 17648.1541 - val_mean_absolute_error: 17648.1543\n",
      "Epoch 456/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 11719.6199 - mean_absolute_error: 11719.6201 - val_loss: 17688.1707 - val_mean_absolute_error: 17688.1719\n",
      "Epoch 457/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 11657.6154 - mean_absolute_error: 11657.6152 - val_loss: 17642.0727 - val_mean_absolute_error: 17642.0723\n",
      "Epoch 458/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 11683.6302 - mean_absolute_error: 11683.6318 - val_loss: 17568.2356 - val_mean_absolute_error: 17568.2344\n",
      "Epoch 459/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 11727.7226 - mean_absolute_error: 11727.7236 - val_loss: 17620.2412 - val_mean_absolute_error: 17620.2402\n",
      "Epoch 460/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 11631.4453 - mean_absolute_error: 11631.4453 - val_loss: 17605.0545 - val_mean_absolute_error: 17605.0527\n",
      "Epoch 461/500\n",
      "1168/1168 [==============================] - 0s 74us/step - loss: 11645.8573 - mean_absolute_error: 11645.8574 - val_loss: 17689.0055 - val_mean_absolute_error: 17689.0059\n",
      "Epoch 462/500\n",
      "1168/1168 [==============================] - 0s 74us/step - loss: 11655.1772 - mean_absolute_error: 11655.1768 - val_loss: 17641.0942 - val_mean_absolute_error: 17641.0938\n",
      "Epoch 463/500\n",
      "1168/1168 [==============================] - 0s 74us/step - loss: 11680.3976 - mean_absolute_error: 11680.3984 - val_loss: 17663.7876 - val_mean_absolute_error: 17663.7871\n",
      "Epoch 464/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 11646.5069 - mean_absolute_error: 11646.5068 - val_loss: 17641.5075 - val_mean_absolute_error: 17641.5059\n",
      "Epoch 465/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 11621.9986 - mean_absolute_error: 11621.9990 - val_loss: 17580.6730 - val_mean_absolute_error: 17580.6738\n",
      "Epoch 466/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 11647.3801 - mean_absolute_error: 11647.3799 - val_loss: 17632.7982 - val_mean_absolute_error: 17632.7988\n",
      "Epoch 467/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 11634.4385 - mean_absolute_error: 11634.4395 - val_loss: 17690.2291 - val_mean_absolute_error: 17690.2285\n",
      "Epoch 468/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 11580.2139 - mean_absolute_error: 11580.2139 - val_loss: 17684.8172 - val_mean_absolute_error: 17684.8164\n",
      "Epoch 469/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 11642.4991 - mean_absolute_error: 11642.4990 - val_loss: 17712.9767 - val_mean_absolute_error: 17712.9785\n",
      "Epoch 470/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 11707.6195 - mean_absolute_error: 11707.6211 - val_loss: 17596.4915 - val_mean_absolute_error: 17596.4922\n",
      "Epoch 471/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 11577.6480 - mean_absolute_error: 11577.6494 - val_loss: 17603.7433 - val_mean_absolute_error: 17603.7422\n",
      "Epoch 472/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 11583.6755 - mean_absolute_error: 11583.6758 - val_loss: 17618.3523 - val_mean_absolute_error: 17618.3535\n",
      "Epoch 473/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 11551.8997 - mean_absolute_error: 11551.8994 - val_loss: 17568.9434 - val_mean_absolute_error: 17568.9414\n",
      "Epoch 474/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 11576.2536 - mean_absolute_error: 11576.2549 - val_loss: 17686.2823 - val_mean_absolute_error: 17686.2832\n",
      "Epoch 475/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 11602.5857 - mean_absolute_error: 11602.5859 - val_loss: 17574.7103 - val_mean_absolute_error: 17574.7090\n",
      "Epoch 476/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 11626.1369 - mean_absolute_error: 11626.1367 - val_loss: 17601.2756 - val_mean_absolute_error: 17601.2773\n",
      "Epoch 477/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 11568.3619 - mean_absolute_error: 11568.3633 - val_loss: 17597.5261 - val_mean_absolute_error: 17597.5273\n",
      "Epoch 478/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 11570.3889 - mean_absolute_error: 11570.3887 - val_loss: 17650.1277 - val_mean_absolute_error: 17650.1270\n",
      "Epoch 479/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11593.3068 - mean_absolute_error: 11593.3066 - val_loss: 17519.4225 - val_mean_absolute_error: 17519.4238\n",
      "Epoch 480/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 11554.0771 - mean_absolute_error: 11554.0771 - val_loss: 17593.0247 - val_mean_absolute_error: 17593.0254\n",
      "Epoch 481/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 11569.8557 - mean_absolute_error: 11569.8555 - val_loss: 17632.2071 - val_mean_absolute_error: 17632.2070\n",
      "Epoch 482/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 11559.2131 - mean_absolute_error: 11559.2119 - val_loss: 17535.5860 - val_mean_absolute_error: 17535.5859\n",
      "Epoch 483/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 11570.1838 - mean_absolute_error: 11570.1836 - val_loss: 17543.6588 - val_mean_absolute_error: 17543.6582\n",
      "Epoch 484/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 73us/step - loss: 11519.8313 - mean_absolute_error: 11519.8320 - val_loss: 17579.6064 - val_mean_absolute_error: 17579.6035\n",
      "Epoch 485/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 11567.9464 - mean_absolute_error: 11567.9482 - val_loss: 17572.6263 - val_mean_absolute_error: 17572.6270\n",
      "Epoch 486/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11586.3086 - mean_absolute_error: 11586.3096 - val_loss: 17596.4968 - val_mean_absolute_error: 17596.4961\n",
      "Epoch 487/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 11548.2333 - mean_absolute_error: 11548.2334 - val_loss: 17583.0552 - val_mean_absolute_error: 17583.0566\n",
      "Epoch 488/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11503.9598 - mean_absolute_error: 11503.9619 - val_loss: 17536.7306 - val_mean_absolute_error: 17536.7305\n",
      "Epoch 489/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11497.2276 - mean_absolute_error: 11497.2275 - val_loss: 17567.2107 - val_mean_absolute_error: 17567.2129\n",
      "Epoch 490/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 11498.3580 - mean_absolute_error: 11498.3584 - val_loss: 17564.5961 - val_mean_absolute_error: 17564.5977\n",
      "Epoch 491/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11482.2335 - mean_absolute_error: 11482.2324 - val_loss: 17616.3309 - val_mean_absolute_error: 17616.3301\n",
      "Epoch 492/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11503.1162 - mean_absolute_error: 11503.1162 - val_loss: 17580.8984 - val_mean_absolute_error: 17580.8984\n",
      "Epoch 493/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 11480.2948 - mean_absolute_error: 11480.2949 - val_loss: 17573.8478 - val_mean_absolute_error: 17573.8477\n",
      "Epoch 494/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 11520.3293 - mean_absolute_error: 11520.3291 - val_loss: 17705.9452 - val_mean_absolute_error: 17705.9453\n",
      "Epoch 495/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11499.5725 - mean_absolute_error: 11499.5742 - val_loss: 17527.4845 - val_mean_absolute_error: 17527.4863\n",
      "Epoch 496/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 11488.5855 - mean_absolute_error: 11488.5859 - val_loss: 17536.4100 - val_mean_absolute_error: 17536.4102\n",
      "Epoch 497/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 11453.0923 - mean_absolute_error: 11453.0938 - val_loss: 17597.7460 - val_mean_absolute_error: 17597.7461\n",
      "Epoch 498/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11468.2729 - mean_absolute_error: 11468.2725 - val_loss: 17610.6577 - val_mean_absolute_error: 17610.6582\n",
      "Epoch 499/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 11466.3686 - mean_absolute_error: 11466.3691 - val_loss: 17571.3624 - val_mean_absolute_error: 17571.3633\n",
      "Epoch 500/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 11461.2798 - mean_absolute_error: 11461.2793 - val_loss: 17527.0099 - val_mean_absolute_error: 17527.0117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2418122b208>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=500,batch_size=32,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[207971.92],\n",
       "       [196107.61],\n",
       "       [210215.77],\n",
       "       [165713.92],\n",
       "       [287496.62]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X,y)\n",
    "y_hat_lr = lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([207659.14761438, 205992.9069924 , 205791.63040861, 165907.52281102,\n",
       "       290786.73189639])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_lr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(r'.\\kaggle\\housing\\house-prices-advanced-regression-techniques\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
       "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
       "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
       "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
       "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
       "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
       "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
       "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
       "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
       "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
       "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
       "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
       "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
       "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
       "       'SaleCondition'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preproc = full_Pipeline.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
