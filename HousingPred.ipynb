{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\adb\\\\iCloudDrive\\\\Adnan PC\\\\Data Science\\\\Jupyter NB\\\\kaggle\\\\housing\\\\housing_NN'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'.\\train.csv')\n",
    "test = pd.read_csv(r'.\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.iloc[:,:-1]\n",
    "train_y = train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = list(train_X.describe().columns)\n",
    "cat_col = list(set(train_X.columns).difference(num_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "        \n",
    "def col_remove(df):\n",
    "    dropped_col_list = ['Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature']\n",
    "    for col in dropped_col_list:\n",
    "        if col in df.columns:\n",
    "            df = df.drop(columns=col,axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_na(X):\n",
    "    X = X.fillna(X.mode().iloc[0])\n",
    "    return np.c_[X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "num_Pipeline = Pipeline([\n",
    "#     ('attr_rem',FunctionTransformer(col_remove,validate=False)),\n",
    "    ('fill_na',FunctionTransformer(fix_na,validate=False)),\n",
    "    ('imputer',SimpleImputer(strategy='median')),\n",
    "    ('std_scaler',StandardScaler()),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_Pipeline = Pipeline([\n",
    "#     ('attr_rem',FunctionTransformer(col_remove,validate=False)),\n",
    "    ('fill_na',FunctionTransformer(fix_na,validate=False)),    \n",
    "    ('cat_enc',OneHotEncoder())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "full_Pipeline = ColumnTransformer([\n",
    "    ('num',num_Pipeline,num_col),\n",
    "    ('cat',cat_Pipeline,cat_col),\n",
    "])\n",
    "\n",
    "housing_preproc = full_Pipeline.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = housing_preproc\n",
    "y= train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\adb\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\adb\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\adb\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\adb\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\adb\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\adb\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\adb\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\adb\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\adb\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\adb\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\adb\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\adb\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                9280      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 13,633\n",
      "Trainable params: 13,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Input Layer\n",
    "model.add(Dense(32,kernel_initializer='normal',input_dim=X.shape[1],activation='relu'))\n",
    "model.add(Dense(128, kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(1,kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "model.compile(loss='mean_absolute_error',optimizer='adam',metrics=['mean_absolute_error'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\adb\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1168 samples, validate on 292 samples\n",
      "Epoch 1/500\n",
      "1168/1168 [==============================] - 0s 174us/step - loss: 180587.4899 - mean_absolute_error: 180587.5000 - val_loss: 182233.9619 - val_mean_absolute_error: 182233.9688\n",
      "Epoch 2/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 180541.9964 - mean_absolute_error: 180542.0000 - val_loss: 182129.8996 - val_mean_absolute_error: 182129.9062\n",
      "Epoch 3/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 180309.7526 - mean_absolute_error: 180309.7500 - val_loss: 181736.5659 - val_mean_absolute_error: 181736.5625\n",
      "Epoch 4/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 179643.4995 - mean_absolute_error: 179643.4844 - val_loss: 180784.0509 - val_mean_absolute_error: 180784.0625\n",
      "Epoch 5/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 178251.7410 - mean_absolute_error: 178251.7188 - val_loss: 178990.8908 - val_mean_absolute_error: 178990.8750\n",
      "Epoch 6/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 175843.5111 - mean_absolute_error: 175843.5000 - val_loss: 176083.8127 - val_mean_absolute_error: 176083.8125\n",
      "Epoch 7/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 172139.4217 - mean_absolute_error: 172139.3906 - val_loss: 171800.9035 - val_mean_absolute_error: 171800.9062\n",
      "Epoch 8/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 166870.7911 - mean_absolute_error: 166870.7969 - val_loss: 165886.4788 - val_mean_absolute_error: 165886.4531\n",
      "Epoch 9/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 159778.5449 - mean_absolute_error: 159778.5469 - val_loss: 158109.4957 - val_mean_absolute_error: 158109.5000\n",
      "Epoch 10/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 150617.5417 - mean_absolute_error: 150617.5781 - val_loss: 148226.5899 - val_mean_absolute_error: 148226.5938\n",
      "Epoch 11/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 139194.9067 - mean_absolute_error: 139194.9375 - val_loss: 136084.7387 - val_mean_absolute_error: 136084.7188\n",
      "Epoch 12/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 125395.0294 - mean_absolute_error: 125395.0312 - val_loss: 121540.3014 - val_mean_absolute_error: 121540.3047\n",
      "Epoch 13/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 109175.0432 - mean_absolute_error: 109175.0547 - val_loss: 104921.2922 - val_mean_absolute_error: 104921.2969\n",
      "Epoch 14/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 91385.4462 - mean_absolute_error: 91385.4375 - val_loss: 87240.2956 - val_mean_absolute_error: 87240.3047\n",
      "Epoch 15/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 74353.5912 - mean_absolute_error: 74353.5859 - val_loss: 70540.7010 - val_mean_absolute_error: 70540.7031\n",
      "Epoch 16/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 60516.2290 - mean_absolute_error: 60516.2266 - val_loss: 57773.7145 - val_mean_absolute_error: 57773.7188\n",
      "Epoch 17/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 51542.8224 - mean_absolute_error: 51542.8242 - val_loss: 50230.7501 - val_mean_absolute_error: 50230.7500\n",
      "Epoch 18/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 46216.7360 - mean_absolute_error: 46216.7344 - val_loss: 45748.5336 - val_mean_absolute_error: 45748.5312\n",
      "Epoch 19/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 42387.2816 - mean_absolute_error: 42387.2773 - val_loss: 42305.6015 - val_mean_absolute_error: 42305.6016\n",
      "Epoch 20/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 39355.4201 - mean_absolute_error: 39355.4219 - val_loss: 39643.4725 - val_mean_absolute_error: 39643.4727\n",
      "Epoch 21/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 36774.1555 - mean_absolute_error: 36774.1562 - val_loss: 37296.7061 - val_mean_absolute_error: 37296.7070\n",
      "Epoch 22/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 34484.0244 - mean_absolute_error: 34484.0156 - val_loss: 35389.9537 - val_mean_absolute_error: 35389.9570\n",
      "Epoch 23/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 32447.0986 - mean_absolute_error: 32447.0996 - val_loss: 33802.2168 - val_mean_absolute_error: 33802.2148\n",
      "Epoch 24/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 30629.0962 - mean_absolute_error: 30629.0996 - val_loss: 32273.9020 - val_mean_absolute_error: 32273.9004\n",
      "Epoch 25/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 28982.2808 - mean_absolute_error: 28982.2812 - val_loss: 31006.0276 - val_mean_absolute_error: 31006.0273\n",
      "Epoch 26/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 27558.0829 - mean_absolute_error: 27558.0820 - val_loss: 29931.5056 - val_mean_absolute_error: 29931.5039\n",
      "Epoch 27/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 26330.4847 - mean_absolute_error: 26330.4844 - val_loss: 28684.7622 - val_mean_absolute_error: 28684.7598\n",
      "Epoch 28/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 25316.9486 - mean_absolute_error: 25316.9492 - val_loss: 28134.2319 - val_mean_absolute_error: 28134.2344\n",
      "Epoch 29/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 24443.8854 - mean_absolute_error: 24443.8828 - val_loss: 27396.9069 - val_mean_absolute_error: 27396.9102\n",
      "Epoch 30/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 23767.4269 - mean_absolute_error: 23767.4277 - val_loss: 26787.5509 - val_mean_absolute_error: 26787.5488\n",
      "Epoch 31/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 23179.9198 - mean_absolute_error: 23179.9180 - val_loss: 26441.1968 - val_mean_absolute_error: 26441.1953\n",
      "Epoch 32/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 22696.9315 - mean_absolute_error: 22696.9316 - val_loss: 25990.5700 - val_mean_absolute_error: 25990.5684\n",
      "Epoch 33/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 22270.4523 - mean_absolute_error: 22270.4512 - val_loss: 25620.7170 - val_mean_absolute_error: 25620.7148\n",
      "Epoch 34/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 21894.7394 - mean_absolute_error: 21894.7402 - val_loss: 25237.2693 - val_mean_absolute_error: 25237.2695\n",
      "Epoch 35/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 21571.6707 - mean_absolute_error: 21571.6699 - val_loss: 25002.0905 - val_mean_absolute_error: 25002.0898\n",
      "Epoch 36/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 21265.2654 - mean_absolute_error: 21265.2656 - val_loss: 24501.9553 - val_mean_absolute_error: 24501.9531\n",
      "Epoch 37/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 20993.6483 - mean_absolute_error: 20993.6484 - val_loss: 24265.3779 - val_mean_absolute_error: 24265.3789\n",
      "Epoch 38/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 20733.1236 - mean_absolute_error: 20733.1230 - val_loss: 24138.5752 - val_mean_absolute_error: 24138.5762\n",
      "Epoch 39/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 20481.6839 - mean_absolute_error: 20481.6836 - val_loss: 23997.2429 - val_mean_absolute_error: 23997.2422\n",
      "Epoch 40/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 20257.2143 - mean_absolute_error: 20257.2129 - val_loss: 23742.0891 - val_mean_absolute_error: 23742.0898\n",
      "Epoch 41/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 20028.5396 - mean_absolute_error: 20028.5371 - val_loss: 23568.1534 - val_mean_absolute_error: 23568.1543\n",
      "Epoch 42/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 19811.9251 - mean_absolute_error: 19811.9238 - val_loss: 23352.1223 - val_mean_absolute_error: 23352.1230\n",
      "Epoch 43/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 19618.5576 - mean_absolute_error: 19618.5605 - val_loss: 23244.3175 - val_mean_absolute_error: 23244.3184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 19439.3415 - mean_absolute_error: 19439.3418 - val_loss: 23089.3075 - val_mean_absolute_error: 23089.3086\n",
      "Epoch 45/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 19303.0758 - mean_absolute_error: 19303.0762 - val_loss: 22955.2616 - val_mean_absolute_error: 22955.2637\n",
      "Epoch 46/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 19100.2872 - mean_absolute_error: 19100.2891 - val_loss: 22651.0211 - val_mean_absolute_error: 22651.0195\n",
      "Epoch 47/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 18948.4213 - mean_absolute_error: 18948.4219 - val_loss: 22740.2574 - val_mean_absolute_error: 22740.2578\n",
      "Epoch 48/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 18813.2771 - mean_absolute_error: 18813.2773 - val_loss: 22479.0886 - val_mean_absolute_error: 22479.0879\n",
      "Epoch 49/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 18624.9639 - mean_absolute_error: 18624.9648 - val_loss: 22314.6470 - val_mean_absolute_error: 22314.6465\n",
      "Epoch 50/500\n",
      "1168/1168 [==============================] - 0s 60us/step - loss: 18458.3772 - mean_absolute_error: 18458.3750 - val_loss: 22230.5001 - val_mean_absolute_error: 22230.4980\n",
      "Epoch 51/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 18321.6759 - mean_absolute_error: 18321.6738 - val_loss: 22095.2795 - val_mean_absolute_error: 22095.2812\n",
      "Epoch 52/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 18180.9881 - mean_absolute_error: 18180.9902 - val_loss: 22039.0963 - val_mean_absolute_error: 22039.0957\n",
      "Epoch 53/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 18044.9458 - mean_absolute_error: 18044.9473 - val_loss: 21890.1047 - val_mean_absolute_error: 21890.1035\n",
      "Epoch 54/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 17928.8747 - mean_absolute_error: 17928.8750 - val_loss: 21865.4079 - val_mean_absolute_error: 21865.4082\n",
      "Epoch 55/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 17789.3637 - mean_absolute_error: 17789.3633 - val_loss: 21682.2366 - val_mean_absolute_error: 21682.2344\n",
      "Epoch 56/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 17666.5989 - mean_absolute_error: 17666.5977 - val_loss: 21588.5174 - val_mean_absolute_error: 21588.5195\n",
      "Epoch 57/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 17551.3158 - mean_absolute_error: 17551.3125 - val_loss: 21688.5173 - val_mean_absolute_error: 21688.5176\n",
      "Epoch 58/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 17450.8123 - mean_absolute_error: 17450.8125 - val_loss: 21367.3330 - val_mean_absolute_error: 21367.3301\n",
      "Epoch 59/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 17329.3298 - mean_absolute_error: 17329.3281 - val_loss: 21339.7010 - val_mean_absolute_error: 21339.7012\n",
      "Epoch 60/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 17223.2108 - mean_absolute_error: 17223.2090 - val_loss: 21254.2234 - val_mean_absolute_error: 21254.2246\n",
      "Epoch 61/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 17104.7042 - mean_absolute_error: 17104.7070 - val_loss: 21234.7998 - val_mean_absolute_error: 21234.8008\n",
      "Epoch 62/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 17031.8511 - mean_absolute_error: 17031.8496 - val_loss: 21203.3666 - val_mean_absolute_error: 21203.3672\n",
      "Epoch 63/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 16917.8757 - mean_absolute_error: 16917.8750 - val_loss: 21081.3221 - val_mean_absolute_error: 21081.3223\n",
      "Epoch 64/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 16810.1722 - mean_absolute_error: 16810.1719 - val_loss: 20931.3303 - val_mean_absolute_error: 20931.3301\n",
      "Epoch 65/500\n",
      "1168/1168 [==============================] - 0s 60us/step - loss: 16705.8596 - mean_absolute_error: 16705.8594 - val_loss: 20858.8380 - val_mean_absolute_error: 20858.8379\n",
      "Epoch 66/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 16618.8152 - mean_absolute_error: 16618.8145 - val_loss: 20798.5344 - val_mean_absolute_error: 20798.5352\n",
      "Epoch 67/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 16554.8406 - mean_absolute_error: 16554.8398 - val_loss: 20741.6917 - val_mean_absolute_error: 20741.6895\n",
      "Epoch 68/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 16443.0192 - mean_absolute_error: 16443.0195 - val_loss: 20660.2185 - val_mean_absolute_error: 20660.2188\n",
      "Epoch 69/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 16359.2508 - mean_absolute_error: 16359.2520 - val_loss: 20573.6084 - val_mean_absolute_error: 20573.6074\n",
      "Epoch 70/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 16312.0115 - mean_absolute_error: 16312.0117 - val_loss: 20541.8124 - val_mean_absolute_error: 20541.8125\n",
      "Epoch 71/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 16223.4940 - mean_absolute_error: 16223.4951 - val_loss: 20455.5397 - val_mean_absolute_error: 20455.5391\n",
      "Epoch 72/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 16143.1215 - mean_absolute_error: 16143.1211 - val_loss: 20508.1237 - val_mean_absolute_error: 20508.1230\n",
      "Epoch 73/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 16056.3588 - mean_absolute_error: 16056.3574 - val_loss: 20327.0369 - val_mean_absolute_error: 20327.0371\n",
      "Epoch 74/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 15998.7125 - mean_absolute_error: 15998.7119 - val_loss: 20271.2150 - val_mean_absolute_error: 20271.2148\n",
      "Epoch 75/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 15921.8114 - mean_absolute_error: 15921.8115 - val_loss: 20241.1294 - val_mean_absolute_error: 20241.1309\n",
      "Epoch 76/500\n",
      "1168/1168 [==============================] - 0s 60us/step - loss: 15848.3322 - mean_absolute_error: 15848.3320 - val_loss: 20185.2351 - val_mean_absolute_error: 20185.2344\n",
      "Epoch 77/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 15783.3804 - mean_absolute_error: 15783.3770 - val_loss: 20152.8192 - val_mean_absolute_error: 20152.8184\n",
      "Epoch 78/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 15732.2747 - mean_absolute_error: 15732.2754 - val_loss: 20111.7875 - val_mean_absolute_error: 20111.7871\n",
      "Epoch 79/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 15701.2027 - mean_absolute_error: 15701.2021 - val_loss: 20078.6782 - val_mean_absolute_error: 20078.6797\n",
      "Epoch 80/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 15603.6904 - mean_absolute_error: 15603.6904 - val_loss: 20006.8705 - val_mean_absolute_error: 20006.8711\n",
      "Epoch 81/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 15536.3914 - mean_absolute_error: 15536.3926 - val_loss: 19974.2575 - val_mean_absolute_error: 19974.2578\n",
      "Epoch 82/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 15523.8455 - mean_absolute_error: 15523.8457 - val_loss: 19957.1717 - val_mean_absolute_error: 19957.1719\n",
      "Epoch 83/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 15445.2670 - mean_absolute_error: 15445.2676 - val_loss: 19896.4204 - val_mean_absolute_error: 19896.4219\n",
      "Epoch 84/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 15373.8862 - mean_absolute_error: 15373.8867 - val_loss: 19840.2959 - val_mean_absolute_error: 19840.2969\n",
      "Epoch 85/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 15331.4330 - mean_absolute_error: 15331.4297 - val_loss: 19816.8928 - val_mean_absolute_error: 19816.8906\n",
      "Epoch 86/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 15271.1125 - mean_absolute_error: 15271.1133 - val_loss: 19774.8295 - val_mean_absolute_error: 19774.8281\n",
      "Epoch 87/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 15229.2481 - mean_absolute_error: 15229.2480 - val_loss: 19745.5575 - val_mean_absolute_error: 19745.5605\n",
      "Epoch 88/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 64us/step - loss: 15189.6750 - mean_absolute_error: 15189.6729 - val_loss: 19718.4294 - val_mean_absolute_error: 19718.4277\n",
      "Epoch 89/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 15173.8774 - mean_absolute_error: 15173.8770 - val_loss: 19681.2085 - val_mean_absolute_error: 19681.2070\n",
      "Epoch 90/500\n",
      "1168/1168 [==============================] - 0s 80us/step - loss: 15097.3478 - mean_absolute_error: 15097.3477 - val_loss: 19635.8160 - val_mean_absolute_error: 19635.8184\n",
      "Epoch 91/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 15056.1178 - mean_absolute_error: 15056.1201 - val_loss: 19623.2507 - val_mean_absolute_error: 19623.2500\n",
      "Epoch 92/500\n",
      "1168/1168 [==============================] - 0s 52us/step - loss: 15025.9853 - mean_absolute_error: 15025.9883 - val_loss: 19574.0804 - val_mean_absolute_error: 19574.0801\n",
      "Epoch 93/500\n",
      "1168/1168 [==============================] - 0s 57us/step - loss: 14976.2972 - mean_absolute_error: 14976.2979 - val_loss: 19542.3896 - val_mean_absolute_error: 19542.3887\n",
      "Epoch 94/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 14944.0004 - mean_absolute_error: 14944.0020 - val_loss: 19513.6894 - val_mean_absolute_error: 19513.6875\n",
      "Epoch 95/500\n",
      "1168/1168 [==============================] - 0s 58us/step - loss: 14895.3906 - mean_absolute_error: 14895.3906 - val_loss: 19492.3965 - val_mean_absolute_error: 19492.3984\n",
      "Epoch 96/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 14869.8255 - mean_absolute_error: 14869.8252 - val_loss: 19449.8318 - val_mean_absolute_error: 19449.8320\n",
      "Epoch 97/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 14810.4109 - mean_absolute_error: 14810.4111 - val_loss: 19434.4210 - val_mean_absolute_error: 19434.4219\n",
      "Epoch 98/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 14794.1189 - mean_absolute_error: 14794.1162 - val_loss: 19381.7882 - val_mean_absolute_error: 19381.7871\n",
      "Epoch 99/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 14749.9570 - mean_absolute_error: 14749.9590 - val_loss: 19369.9124 - val_mean_absolute_error: 19369.9121\n",
      "Epoch 100/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 14706.9889 - mean_absolute_error: 14706.9893 - val_loss: 19335.2566 - val_mean_absolute_error: 19335.2578\n",
      "Epoch 101/500\n",
      "1168/1168 [==============================] - 0s 58us/step - loss: 14673.6559 - mean_absolute_error: 14673.6562 - val_loss: 19307.0218 - val_mean_absolute_error: 19307.0215\n",
      "Epoch 102/500\n",
      "1168/1168 [==============================] - 0s 59us/step - loss: 14656.0617 - mean_absolute_error: 14656.0596 - val_loss: 19275.7519 - val_mean_absolute_error: 19275.7520\n",
      "Epoch 103/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 14635.2634 - mean_absolute_error: 14635.2656 - val_loss: 19259.6019 - val_mean_absolute_error: 19259.6016\n",
      "Epoch 104/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 14602.8387 - mean_absolute_error: 14602.8408 - val_loss: 19239.8524 - val_mean_absolute_error: 19239.8535\n",
      "Epoch 105/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 14563.9000 - mean_absolute_error: 14563.9004 - val_loss: 19217.7889 - val_mean_absolute_error: 19217.7871\n",
      "Epoch 106/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 14529.5610 - mean_absolute_error: 14529.5596 - val_loss: 19200.5360 - val_mean_absolute_error: 19200.5352\n",
      "Epoch 107/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 14493.5752 - mean_absolute_error: 14493.5752 - val_loss: 19185.7401 - val_mean_absolute_error: 19185.7383\n",
      "Epoch 108/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 14480.3179 - mean_absolute_error: 14480.3184 - val_loss: 19151.9225 - val_mean_absolute_error: 19151.9238\n",
      "Epoch 109/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 14464.7167 - mean_absolute_error: 14464.7188 - val_loss: 19138.2897 - val_mean_absolute_error: 19138.2871\n",
      "Epoch 110/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 14418.4962 - mean_absolute_error: 14418.4951 - val_loss: 19116.6850 - val_mean_absolute_error: 19116.6855\n",
      "Epoch 111/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 14389.4046 - mean_absolute_error: 14389.4043 - val_loss: 19096.7515 - val_mean_absolute_error: 19096.7520\n",
      "Epoch 112/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 14352.8527 - mean_absolute_error: 14352.8516 - val_loss: 19070.3044 - val_mean_absolute_error: 19070.3008\n",
      "Epoch 113/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 14335.6045 - mean_absolute_error: 14335.6035 - val_loss: 19047.4669 - val_mean_absolute_error: 19047.4648\n",
      "Epoch 114/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 14306.4970 - mean_absolute_error: 14306.4961 - val_loss: 19048.3312 - val_mean_absolute_error: 19048.3301\n",
      "Epoch 115/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 14303.3729 - mean_absolute_error: 14303.3730 - val_loss: 19021.8343 - val_mean_absolute_error: 19021.8340\n",
      "Epoch 116/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 14265.5839 - mean_absolute_error: 14265.5840 - val_loss: 19001.1465 - val_mean_absolute_error: 19001.1484\n",
      "Epoch 117/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 14273.6676 - mean_absolute_error: 14273.6650 - val_loss: 19004.9205 - val_mean_absolute_error: 19004.9238\n",
      "Epoch 118/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 14238.5308 - mean_absolute_error: 14238.5312 - val_loss: 18967.3525 - val_mean_absolute_error: 18967.3535\n",
      "Epoch 119/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 14202.1307 - mean_absolute_error: 14202.1299 - val_loss: 18944.8605 - val_mean_absolute_error: 18944.8594\n",
      "Epoch 120/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 14167.1072 - mean_absolute_error: 14167.1074 - val_loss: 18930.1617 - val_mean_absolute_error: 18930.1621\n",
      "Epoch 121/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 14147.5184 - mean_absolute_error: 14147.5166 - val_loss: 18922.7071 - val_mean_absolute_error: 18922.7090\n",
      "Epoch 122/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 14123.8273 - mean_absolute_error: 14123.8291 - val_loss: 18912.4118 - val_mean_absolute_error: 18912.4102\n",
      "Epoch 123/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 14125.6330 - mean_absolute_error: 14125.6328 - val_loss: 18897.6414 - val_mean_absolute_error: 18897.6445\n",
      "Epoch 124/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 14083.1668 - mean_absolute_error: 14083.1650 - val_loss: 18905.8486 - val_mean_absolute_error: 18905.8477\n",
      "Epoch 125/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 14070.8834 - mean_absolute_error: 14070.8838 - val_loss: 18863.8627 - val_mean_absolute_error: 18863.8633\n",
      "Epoch 126/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 14070.6909 - mean_absolute_error: 14070.6914 - val_loss: 18829.6108 - val_mean_absolute_error: 18829.6113\n",
      "Epoch 127/500\n",
      "1168/1168 [==============================] - 0s 60us/step - loss: 14055.2429 - mean_absolute_error: 14055.2451 - val_loss: 18844.3146 - val_mean_absolute_error: 18844.3145\n",
      "Epoch 128/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 14010.1891 - mean_absolute_error: 14010.1885 - val_loss: 18803.2927 - val_mean_absolute_error: 18803.2910\n",
      "Epoch 129/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 14024.5239 - mean_absolute_error: 14024.5244 - val_loss: 18779.2633 - val_mean_absolute_error: 18779.2656\n",
      "Epoch 130/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 13984.7368 - mean_absolute_error: 13984.7344 - val_loss: 18767.4146 - val_mean_absolute_error: 18767.4121\n",
      "Epoch 131/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 13957.4269 - mean_absolute_error: 13957.4268 - val_loss: 18742.9854 - val_mean_absolute_error: 18742.9844\n",
      "Epoch 132/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 61us/step - loss: 13955.4235 - mean_absolute_error: 13955.4229 - val_loss: 18739.2135 - val_mean_absolute_error: 18739.2129\n",
      "Epoch 133/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 13941.7002 - mean_absolute_error: 13941.7012 - val_loss: 18723.0543 - val_mean_absolute_error: 18723.0547\n",
      "Epoch 134/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 13907.5025 - mean_absolute_error: 13907.5020 - val_loss: 18706.0072 - val_mean_absolute_error: 18706.0059\n",
      "Epoch 135/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 13894.9700 - mean_absolute_error: 13894.9688 - val_loss: 18705.9987 - val_mean_absolute_error: 18705.9980\n",
      "Epoch 136/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 13881.5774 - mean_absolute_error: 13881.5762 - val_loss: 18711.3304 - val_mean_absolute_error: 18711.3301\n",
      "Epoch 137/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 13861.1621 - mean_absolute_error: 13861.1611 - val_loss: 18664.4789 - val_mean_absolute_error: 18664.4805\n",
      "Epoch 138/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 13869.9397 - mean_absolute_error: 13869.9424 - val_loss: 18653.9955 - val_mean_absolute_error: 18653.9941\n",
      "Epoch 139/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 13839.6493 - mean_absolute_error: 13839.6494 - val_loss: 18651.9576 - val_mean_absolute_error: 18651.9590\n",
      "Epoch 140/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 13822.7888 - mean_absolute_error: 13822.7910 - val_loss: 18636.5526 - val_mean_absolute_error: 18636.5508\n",
      "Epoch 141/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 13801.4164 - mean_absolute_error: 13801.4180 - val_loss: 18627.4450 - val_mean_absolute_error: 18627.4434\n",
      "Epoch 142/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 13790.7940 - mean_absolute_error: 13790.7949 - val_loss: 18613.8225 - val_mean_absolute_error: 18613.8223\n",
      "Epoch 143/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 13782.5993 - mean_absolute_error: 13782.5977 - val_loss: 18599.2817 - val_mean_absolute_error: 18599.2832\n",
      "Epoch 144/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 13772.0637 - mean_absolute_error: 13772.0654 - val_loss: 18592.6436 - val_mean_absolute_error: 18592.6445\n",
      "Epoch 145/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 13781.8356 - mean_absolute_error: 13781.8359 - val_loss: 18579.2625 - val_mean_absolute_error: 18579.2637\n",
      "Epoch 146/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 13776.9148 - mean_absolute_error: 13776.9131 - val_loss: 18572.8554 - val_mean_absolute_error: 18572.8574\n",
      "Epoch 147/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 13724.8644 - mean_absolute_error: 13724.8623 - val_loss: 18577.3482 - val_mean_absolute_error: 18577.3477\n",
      "Epoch 148/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 13725.5742 - mean_absolute_error: 13725.5742 - val_loss: 18556.0204 - val_mean_absolute_error: 18556.0195\n",
      "Epoch 149/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 13702.9354 - mean_absolute_error: 13702.9355 - val_loss: 18545.5896 - val_mean_absolute_error: 18545.5898\n",
      "Epoch 150/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 13686.5591 - mean_absolute_error: 13686.5596 - val_loss: 18519.2482 - val_mean_absolute_error: 18519.2480\n",
      "Epoch 151/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 13678.5423 - mean_absolute_error: 13678.5400 - val_loss: 18518.1654 - val_mean_absolute_error: 18518.1660\n",
      "Epoch 152/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 13666.3738 - mean_absolute_error: 13666.3721 - val_loss: 18521.7453 - val_mean_absolute_error: 18521.7461\n",
      "Epoch 153/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 13668.3406 - mean_absolute_error: 13668.3408 - val_loss: 18509.7234 - val_mean_absolute_error: 18509.7246\n",
      "Epoch 154/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 13641.3384 - mean_absolute_error: 13641.3379 - val_loss: 18491.9112 - val_mean_absolute_error: 18491.9102\n",
      "Epoch 155/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 13647.6529 - mean_absolute_error: 13647.6533 - val_loss: 18500.4304 - val_mean_absolute_error: 18500.4297\n",
      "Epoch 156/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 13622.6330 - mean_absolute_error: 13622.6328 - val_loss: 18490.2700 - val_mean_absolute_error: 18490.2715\n",
      "Epoch 157/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 13603.8956 - mean_absolute_error: 13603.8975 - val_loss: 18456.5635 - val_mean_absolute_error: 18456.5645\n",
      "Epoch 158/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 13598.8083 - mean_absolute_error: 13598.8086 - val_loss: 18459.3384 - val_mean_absolute_error: 18459.3398\n",
      "Epoch 159/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 13633.9076 - mean_absolute_error: 13633.9072 - val_loss: 18437.5052 - val_mean_absolute_error: 18437.5078\n",
      "Epoch 160/500\n",
      "1168/1168 [==============================] - 0s 75us/step - loss: 13582.7949 - mean_absolute_error: 13582.7959 - val_loss: 18433.6808 - val_mean_absolute_error: 18433.6797\n",
      "Epoch 161/500\n",
      "1168/1168 [==============================] - 0s 60us/step - loss: 13572.7193 - mean_absolute_error: 13572.7188 - val_loss: 18440.7539 - val_mean_absolute_error: 18440.7520\n",
      "Epoch 162/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 13552.5939 - mean_absolute_error: 13552.5938 - val_loss: 18426.2263 - val_mean_absolute_error: 18426.2285\n",
      "Epoch 163/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 13556.7443 - mean_absolute_error: 13556.7461 - val_loss: 18424.5136 - val_mean_absolute_error: 18424.5137\n",
      "Epoch 164/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 13547.3700 - mean_absolute_error: 13547.3701 - val_loss: 18483.9576 - val_mean_absolute_error: 18483.9570\n",
      "Epoch 165/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 13532.6978 - mean_absolute_error: 13532.6953 - val_loss: 18419.1268 - val_mean_absolute_error: 18419.1270\n",
      "Epoch 166/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 13553.8890 - mean_absolute_error: 13553.8877 - val_loss: 18416.2118 - val_mean_absolute_error: 18416.2109\n",
      "Epoch 167/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 13503.8768 - mean_absolute_error: 13503.8760 - val_loss: 18394.1374 - val_mean_absolute_error: 18394.1348\n",
      "Epoch 168/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 13486.9589 - mean_absolute_error: 13486.9609 - val_loss: 18383.8641 - val_mean_absolute_error: 18383.8633\n",
      "Epoch 169/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 13489.9519 - mean_absolute_error: 13489.9521 - val_loss: 18397.6675 - val_mean_absolute_error: 18397.6660\n",
      "Epoch 170/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 13501.4630 - mean_absolute_error: 13501.4629 - val_loss: 18408.1661 - val_mean_absolute_error: 18408.1660\n",
      "Epoch 171/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 13472.7329 - mean_absolute_error: 13472.7334 - val_loss: 18368.9269 - val_mean_absolute_error: 18368.9258\n",
      "Epoch 172/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 13476.7749 - mean_absolute_error: 13476.7754 - val_loss: 18349.0634 - val_mean_absolute_error: 18349.0625\n",
      "Epoch 173/500\n",
      "1168/1168 [==============================] - 0s 58us/step - loss: 13454.9259 - mean_absolute_error: 13454.9258 - val_loss: 18358.6494 - val_mean_absolute_error: 18358.6484\n",
      "Epoch 174/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 13471.0725 - mean_absolute_error: 13471.0732 - val_loss: 18350.2199 - val_mean_absolute_error: 18350.2188\n",
      "Epoch 175/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 13432.6516 - mean_absolute_error: 13432.6504 - val_loss: 18335.9746 - val_mean_absolute_error: 18335.9766\n",
      "Epoch 176/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 62us/step - loss: 13436.5340 - mean_absolute_error: 13436.5332 - val_loss: 18353.2839 - val_mean_absolute_error: 18353.2832\n",
      "Epoch 177/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 13432.2460 - mean_absolute_error: 13432.2461 - val_loss: 18335.3175 - val_mean_absolute_error: 18335.3164\n",
      "Epoch 178/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 13414.8004 - mean_absolute_error: 13414.8018 - val_loss: 18329.5120 - val_mean_absolute_error: 18329.5137\n",
      "Epoch 179/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 13446.7632 - mean_absolute_error: 13446.7627 - val_loss: 18308.6356 - val_mean_absolute_error: 18308.6348\n",
      "Epoch 180/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 13407.6575 - mean_absolute_error: 13407.6562 - val_loss: 18385.0386 - val_mean_absolute_error: 18385.0391\n",
      "Epoch 181/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 13411.3364 - mean_absolute_error: 13411.3359 - val_loss: 18311.1817 - val_mean_absolute_error: 18311.1816\n",
      "Epoch 182/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 13382.0906 - mean_absolute_error: 13382.0889 - val_loss: 18301.7749 - val_mean_absolute_error: 18301.7754\n",
      "Epoch 183/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 13367.8212 - mean_absolute_error: 13367.8213 - val_loss: 18296.7361 - val_mean_absolute_error: 18296.7383\n",
      "Epoch 184/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 13352.5875 - mean_absolute_error: 13352.5869 - val_loss: 18270.0188 - val_mean_absolute_error: 18270.0176\n",
      "Epoch 185/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 13354.6813 - mean_absolute_error: 13354.6816 - val_loss: 18290.7350 - val_mean_absolute_error: 18290.7363\n",
      "Epoch 186/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 13353.7261 - mean_absolute_error: 13353.7275 - val_loss: 18275.2269 - val_mean_absolute_error: 18275.2285\n",
      "Epoch 187/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 13325.9183 - mean_absolute_error: 13325.9199 - val_loss: 18251.1664 - val_mean_absolute_error: 18251.1660\n",
      "Epoch 188/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 13347.8743 - mean_absolute_error: 13347.8760 - val_loss: 18250.8197 - val_mean_absolute_error: 18250.8184\n",
      "Epoch 189/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 13339.8117 - mean_absolute_error: 13339.8135 - val_loss: 18243.8447 - val_mean_absolute_error: 18243.8438\n",
      "Epoch 190/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 13314.9544 - mean_absolute_error: 13314.9541 - val_loss: 18276.3488 - val_mean_absolute_error: 18276.3477\n",
      "Epoch 191/500\n",
      "1168/1168 [==============================] - 0s 60us/step - loss: 13308.9130 - mean_absolute_error: 13308.9131 - val_loss: 18222.2820 - val_mean_absolute_error: 18222.2812\n",
      "Epoch 192/500\n",
      "1168/1168 [==============================] - 0s 59us/step - loss: 13303.8359 - mean_absolute_error: 13303.8350 - val_loss: 18241.9521 - val_mean_absolute_error: 18241.9531\n",
      "Epoch 193/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 13298.2850 - mean_absolute_error: 13298.2861 - val_loss: 18223.6131 - val_mean_absolute_error: 18223.6133\n",
      "Epoch 194/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 13285.5483 - mean_absolute_error: 13285.5498 - val_loss: 18262.2128 - val_mean_absolute_error: 18262.2129\n",
      "Epoch 195/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 13294.6801 - mean_absolute_error: 13294.6787 - val_loss: 18259.4019 - val_mean_absolute_error: 18259.4004\n",
      "Epoch 196/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 13317.8386 - mean_absolute_error: 13317.8379 - val_loss: 18201.5037 - val_mean_absolute_error: 18201.5039\n",
      "Epoch 197/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 13270.2152 - mean_absolute_error: 13270.2139 - val_loss: 18213.8250 - val_mean_absolute_error: 18213.8242\n",
      "Epoch 198/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 13280.2469 - mean_absolute_error: 13280.2461 - val_loss: 18270.4621 - val_mean_absolute_error: 18270.4629\n",
      "Epoch 199/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 13263.4411 - mean_absolute_error: 13263.4404 - val_loss: 18189.3731 - val_mean_absolute_error: 18189.3730\n",
      "Epoch 200/500\n",
      "1168/1168 [==============================] - 0s 59us/step - loss: 13259.6548 - mean_absolute_error: 13259.6562 - val_loss: 18223.3248 - val_mean_absolute_error: 18223.3242\n",
      "Epoch 201/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 13242.9905 - mean_absolute_error: 13242.9893 - val_loss: 18183.0673 - val_mean_absolute_error: 18183.0684\n",
      "Epoch 202/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 13234.9527 - mean_absolute_error: 13234.9512 - val_loss: 18245.4772 - val_mean_absolute_error: 18245.4766\n",
      "Epoch 203/500\n",
      "1168/1168 [==============================] - 0s 60us/step - loss: 13243.5582 - mean_absolute_error: 13243.5586 - val_loss: 18247.3682 - val_mean_absolute_error: 18247.3691\n",
      "Epoch 204/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 13248.1475 - mean_absolute_error: 13248.1475 - val_loss: 18210.2775 - val_mean_absolute_error: 18210.2793\n",
      "Epoch 205/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 13236.2232 - mean_absolute_error: 13236.2217 - val_loss: 18248.3022 - val_mean_absolute_error: 18248.3008\n",
      "Epoch 206/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 13222.7730 - mean_absolute_error: 13222.7744 - val_loss: 18186.6445 - val_mean_absolute_error: 18186.6465\n",
      "Epoch 207/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 13201.6134 - mean_absolute_error: 13201.6113 - val_loss: 18160.3167 - val_mean_absolute_error: 18160.3164\n",
      "Epoch 208/500\n",
      "1168/1168 [==============================] - 0s 59us/step - loss: 13202.0777 - mean_absolute_error: 13202.0781 - val_loss: 18162.0136 - val_mean_absolute_error: 18162.0137\n",
      "Epoch 209/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 13183.1439 - mean_absolute_error: 13183.1455 - val_loss: 18168.4472 - val_mean_absolute_error: 18168.4473\n",
      "Epoch 210/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 13196.2079 - mean_absolute_error: 13196.2109 - val_loss: 18137.7278 - val_mean_absolute_error: 18137.7285\n",
      "Epoch 211/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 13169.2828 - mean_absolute_error: 13169.2842 - val_loss: 18144.4740 - val_mean_absolute_error: 18144.4766\n",
      "Epoch 212/500\n",
      "1168/1168 [==============================] - 0s 59us/step - loss: 13164.4890 - mean_absolute_error: 13164.4893 - val_loss: 18125.5223 - val_mean_absolute_error: 18125.5234\n",
      "Epoch 213/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 13157.2321 - mean_absolute_error: 13157.2334 - val_loss: 18161.6717 - val_mean_absolute_error: 18161.6738\n",
      "Epoch 214/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 13166.5882 - mean_absolute_error: 13166.5869 - val_loss: 18139.2628 - val_mean_absolute_error: 18139.2617\n",
      "Epoch 215/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 13156.6639 - mean_absolute_error: 13156.6631 - val_loss: 18119.4825 - val_mean_absolute_error: 18119.4824\n",
      "Epoch 216/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 13173.2447 - mean_absolute_error: 13173.2461 - val_loss: 18094.4174 - val_mean_absolute_error: 18094.4180\n",
      "Epoch 217/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 13160.4843 - mean_absolute_error: 13160.4834 - val_loss: 18092.6948 - val_mean_absolute_error: 18092.6934\n",
      "Epoch 218/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 13148.3699 - mean_absolute_error: 13148.3682 - val_loss: 18083.6270 - val_mean_absolute_error: 18083.6289\n",
      "Epoch 219/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 13117.8977 - mean_absolute_error: 13117.8984 - val_loss: 18120.2030 - val_mean_absolute_error: 18120.2012\n",
      "Epoch 220/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 60us/step - loss: 13141.3949 - mean_absolute_error: 13141.3936 - val_loss: 18101.5453 - val_mean_absolute_error: 18101.5469\n",
      "Epoch 221/500\n",
      "1168/1168 [==============================] - 0s 60us/step - loss: 13114.9699 - mean_absolute_error: 13114.9688 - val_loss: 18095.4145 - val_mean_absolute_error: 18095.4141\n",
      "Epoch 222/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 13101.3180 - mean_absolute_error: 13101.3184 - val_loss: 18112.5876 - val_mean_absolute_error: 18112.5898\n",
      "Epoch 223/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 13137.3319 - mean_absolute_error: 13137.3340 - val_loss: 18122.4787 - val_mean_absolute_error: 18122.4785\n",
      "Epoch 224/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 13142.0626 - mean_absolute_error: 13142.0654 - val_loss: 18067.4738 - val_mean_absolute_error: 18067.4746\n",
      "Epoch 225/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 13100.9622 - mean_absolute_error: 13100.9629 - val_loss: 18051.5228 - val_mean_absolute_error: 18051.5234\n",
      "Epoch 226/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 13083.7592 - mean_absolute_error: 13083.7588 - val_loss: 18072.1583 - val_mean_absolute_error: 18072.1582\n",
      "Epoch 227/500\n",
      "1168/1168 [==============================] - 0s 60us/step - loss: 13140.4506 - mean_absolute_error: 13140.4502 - val_loss: 18056.2969 - val_mean_absolute_error: 18056.2988\n",
      "Epoch 228/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 13076.3705 - mean_absolute_error: 13076.3711 - val_loss: 18056.3309 - val_mean_absolute_error: 18056.3301\n",
      "Epoch 229/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 13087.8030 - mean_absolute_error: 13087.8018 - val_loss: 18041.0314 - val_mean_absolute_error: 18041.0332\n",
      "Epoch 230/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 13064.6646 - mean_absolute_error: 13064.6631 - val_loss: 18050.3304 - val_mean_absolute_error: 18050.3281\n",
      "Epoch 231/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 13062.3630 - mean_absolute_error: 13062.3633 - val_loss: 18044.9259 - val_mean_absolute_error: 18044.9277\n",
      "Epoch 232/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 13088.4651 - mean_absolute_error: 13088.4639 - val_loss: 18042.2925 - val_mean_absolute_error: 18042.2930\n",
      "Epoch 233/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 13059.3785 - mean_absolute_error: 13059.3799 - val_loss: 18053.3955 - val_mean_absolute_error: 18053.3965\n",
      "Epoch 234/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 13068.2858 - mean_absolute_error: 13068.2832 - val_loss: 18026.1097 - val_mean_absolute_error: 18026.1113\n",
      "Epoch 235/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 13043.7012 - mean_absolute_error: 13043.6992 - val_loss: 18023.3217 - val_mean_absolute_error: 18023.3223\n",
      "Epoch 236/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 13039.7857 - mean_absolute_error: 13039.7861 - val_loss: 18033.9060 - val_mean_absolute_error: 18033.9062\n",
      "Epoch 237/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 13042.3402 - mean_absolute_error: 13042.3398 - val_loss: 18011.7541 - val_mean_absolute_error: 18011.7559\n",
      "Epoch 238/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 13034.0374 - mean_absolute_error: 13034.0381 - val_loss: 18010.0387 - val_mean_absolute_error: 18010.0410\n",
      "Epoch 239/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 13043.4277 - mean_absolute_error: 13043.4268 - val_loss: 18020.1688 - val_mean_absolute_error: 18020.1680\n",
      "Epoch 240/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 13062.1158 - mean_absolute_error: 13062.1143 - val_loss: 18005.7435 - val_mean_absolute_error: 18005.7422\n",
      "Epoch 241/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 13019.4279 - mean_absolute_error: 13019.4268 - val_loss: 18017.0231 - val_mean_absolute_error: 18017.0215\n",
      "Epoch 242/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 13009.8903 - mean_absolute_error: 13009.8896 - val_loss: 17998.0529 - val_mean_absolute_error: 17998.0547\n",
      "Epoch 243/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 13005.6597 - mean_absolute_error: 13005.6592 - val_loss: 17995.7020 - val_mean_absolute_error: 17995.7012\n",
      "Epoch 244/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 13012.5266 - mean_absolute_error: 13012.5264 - val_loss: 17995.4040 - val_mean_absolute_error: 17995.4062\n",
      "Epoch 245/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12996.6234 - mean_absolute_error: 12996.6221 - val_loss: 18031.4445 - val_mean_absolute_error: 18031.4453\n",
      "Epoch 246/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 13005.1734 - mean_absolute_error: 13005.1748 - val_loss: 18005.9699 - val_mean_absolute_error: 18005.9707\n",
      "Epoch 247/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 13000.4857 - mean_absolute_error: 13000.4854 - val_loss: 17988.8085 - val_mean_absolute_error: 17988.8105\n",
      "Epoch 248/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 12997.5736 - mean_absolute_error: 12997.5742 - val_loss: 17989.3262 - val_mean_absolute_error: 17989.3262\n",
      "Epoch 249/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 12984.9087 - mean_absolute_error: 12984.9072 - val_loss: 17980.9404 - val_mean_absolute_error: 17980.9414\n",
      "Epoch 250/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 12972.6065 - mean_absolute_error: 12972.6064 - val_loss: 17977.3515 - val_mean_absolute_error: 17977.3516\n",
      "Epoch 251/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12982.1593 - mean_absolute_error: 12982.1592 - val_loss: 17970.3566 - val_mean_absolute_error: 17970.3574\n",
      "Epoch 252/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 12998.1064 - mean_absolute_error: 12998.1074 - val_loss: 17969.5159 - val_mean_absolute_error: 17969.5176\n",
      "Epoch 253/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 12958.1178 - mean_absolute_error: 12958.1191 - val_loss: 17979.4998 - val_mean_absolute_error: 17979.5000\n",
      "Epoch 254/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12956.4477 - mean_absolute_error: 12956.4482 - val_loss: 17974.8037 - val_mean_absolute_error: 17974.8047\n",
      "Epoch 255/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 12952.3204 - mean_absolute_error: 12952.3223 - val_loss: 17981.4371 - val_mean_absolute_error: 17981.4375\n",
      "Epoch 256/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 12968.5385 - mean_absolute_error: 12968.5381 - val_loss: 17977.3966 - val_mean_absolute_error: 17977.3965\n",
      "Epoch 257/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12973.3176 - mean_absolute_error: 12973.3184 - val_loss: 18007.2164 - val_mean_absolute_error: 18007.2168\n",
      "Epoch 258/500\n",
      "1168/1168 [==============================] - 0s 58us/step - loss: 12980.8987 - mean_absolute_error: 12980.8975 - val_loss: 17982.8602 - val_mean_absolute_error: 17982.8574\n",
      "Epoch 259/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12946.9938 - mean_absolute_error: 12946.9922 - val_loss: 17974.5321 - val_mean_absolute_error: 17974.5312\n",
      "Epoch 260/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12938.2030 - mean_absolute_error: 12938.2021 - val_loss: 17965.6517 - val_mean_absolute_error: 17965.6523\n",
      "Epoch 261/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 12929.2989 - mean_absolute_error: 12929.2979 - val_loss: 17954.3398 - val_mean_absolute_error: 17954.3398\n",
      "Epoch 262/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 12926.2943 - mean_absolute_error: 12926.2939 - val_loss: 17957.4351 - val_mean_absolute_error: 17957.4375\n",
      "Epoch 263/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 12927.3934 - mean_absolute_error: 12927.3926 - val_loss: 17974.4036 - val_mean_absolute_error: 17974.4043\n",
      "Epoch 264/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 68us/step - loss: 12933.6464 - mean_absolute_error: 12933.6465 - val_loss: 17942.8997 - val_mean_absolute_error: 17942.9004\n",
      "Epoch 265/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12922.7986 - mean_absolute_error: 12922.7988 - val_loss: 17944.6277 - val_mean_absolute_error: 17944.6289\n",
      "Epoch 266/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12908.8834 - mean_absolute_error: 12908.8828 - val_loss: 17972.1690 - val_mean_absolute_error: 17972.1719\n",
      "Epoch 267/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 12921.1141 - mean_absolute_error: 12921.1143 - val_loss: 17961.0944 - val_mean_absolute_error: 17961.0938\n",
      "Epoch 268/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12920.9233 - mean_absolute_error: 12920.9248 - val_loss: 17950.8555 - val_mean_absolute_error: 17950.8535\n",
      "Epoch 269/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12900.2344 - mean_absolute_error: 12900.2324 - val_loss: 17961.0890 - val_mean_absolute_error: 17961.0898\n",
      "Epoch 270/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 12910.5616 - mean_absolute_error: 12910.5605 - val_loss: 17952.1885 - val_mean_absolute_error: 17952.1875\n",
      "Epoch 271/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 12900.8144 - mean_absolute_error: 12900.8164 - val_loss: 17956.0035 - val_mean_absolute_error: 17956.0059\n",
      "Epoch 272/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12893.2103 - mean_absolute_error: 12893.2100 - val_loss: 17959.3935 - val_mean_absolute_error: 17959.3945\n",
      "Epoch 273/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12894.3839 - mean_absolute_error: 12894.3818 - val_loss: 17960.2831 - val_mean_absolute_error: 17960.2852\n",
      "Epoch 274/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 12911.8750 - mean_absolute_error: 12911.8750 - val_loss: 17941.3140 - val_mean_absolute_error: 17941.3125\n",
      "Epoch 275/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12876.3082 - mean_absolute_error: 12876.3086 - val_loss: 17938.0747 - val_mean_absolute_error: 17938.0762\n",
      "Epoch 276/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12900.8734 - mean_absolute_error: 12900.8740 - val_loss: 17943.6469 - val_mean_absolute_error: 17943.6465\n",
      "Epoch 277/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12917.3857 - mean_absolute_error: 12917.3857 - val_loss: 17917.2710 - val_mean_absolute_error: 17917.2695\n",
      "Epoch 278/500\n",
      "1168/1168 [==============================] - 0s 84us/step - loss: 12875.5639 - mean_absolute_error: 12875.5625 - val_loss: 17934.5355 - val_mean_absolute_error: 17934.5352\n",
      "Epoch 279/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 12882.2306 - mean_absolute_error: 12882.2295 - val_loss: 17929.6952 - val_mean_absolute_error: 17929.6953\n",
      "Epoch 280/500\n",
      "1168/1168 [==============================] - 0s 60us/step - loss: 12908.6698 - mean_absolute_error: 12908.6699 - val_loss: 17920.1333 - val_mean_absolute_error: 17920.1328\n",
      "Epoch 281/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12880.6351 - mean_absolute_error: 12880.6357 - val_loss: 17933.6721 - val_mean_absolute_error: 17933.6719\n",
      "Epoch 282/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 12855.5136 - mean_absolute_error: 12855.5137 - val_loss: 17934.5108 - val_mean_absolute_error: 17934.5098\n",
      "Epoch 283/500\n",
      "1168/1168 [==============================] - 0s 59us/step - loss: 12874.4623 - mean_absolute_error: 12874.4629 - val_loss: 17938.0965 - val_mean_absolute_error: 17938.0977\n",
      "Epoch 284/500\n",
      "1168/1168 [==============================] - 0s 56us/step - loss: 12872.9129 - mean_absolute_error: 12872.9121 - val_loss: 17925.0368 - val_mean_absolute_error: 17925.0352\n",
      "Epoch 285/500\n",
      "1168/1168 [==============================] - 0s 81us/step - loss: 12859.5295 - mean_absolute_error: 12859.5312 - val_loss: 17936.2123 - val_mean_absolute_error: 17936.2129\n",
      "Epoch 286/500\n",
      "1168/1168 [==============================] - 0s 90us/step - loss: 12856.0009 - mean_absolute_error: 12856.0010 - val_loss: 17919.5097 - val_mean_absolute_error: 17919.5098\n",
      "Epoch 287/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12843.3959 - mean_absolute_error: 12843.3975 - val_loss: 17922.5304 - val_mean_absolute_error: 17922.5312\n",
      "Epoch 288/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 12837.4988 - mean_absolute_error: 12837.4980 - val_loss: 17922.5097 - val_mean_absolute_error: 17922.5078\n",
      "Epoch 289/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 12836.2692 - mean_absolute_error: 12836.2695 - val_loss: 17923.1414 - val_mean_absolute_error: 17923.1426\n",
      "Epoch 290/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12844.5488 - mean_absolute_error: 12844.5498 - val_loss: 17932.8718 - val_mean_absolute_error: 17932.8711\n",
      "Epoch 291/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12845.1052 - mean_absolute_error: 12845.1055 - val_loss: 17945.1790 - val_mean_absolute_error: 17945.1797\n",
      "Epoch 292/500\n",
      "1168/1168 [==============================] - 0s 57us/step - loss: 12830.4913 - mean_absolute_error: 12830.4912 - val_loss: 17929.1786 - val_mean_absolute_error: 17929.1777\n",
      "Epoch 293/500\n",
      "1168/1168 [==============================] - 0s 56us/step - loss: 12835.2092 - mean_absolute_error: 12835.2100 - val_loss: 17931.2332 - val_mean_absolute_error: 17931.2324\n",
      "Epoch 294/500\n",
      "1168/1168 [==============================] - 0s 56us/step - loss: 12839.6769 - mean_absolute_error: 12839.6768 - val_loss: 17964.4460 - val_mean_absolute_error: 17964.4453\n",
      "Epoch 295/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12836.8346 - mean_absolute_error: 12836.8340 - val_loss: 17976.8587 - val_mean_absolute_error: 17976.8574\n",
      "Epoch 296/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12859.6823 - mean_absolute_error: 12859.6816 - val_loss: 17937.8655 - val_mean_absolute_error: 17937.8672\n",
      "Epoch 297/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12816.8290 - mean_absolute_error: 12816.8281 - val_loss: 17935.4853 - val_mean_absolute_error: 17935.4844\n",
      "Epoch 298/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 12806.5359 - mean_absolute_error: 12806.5352 - val_loss: 18011.4434 - val_mean_absolute_error: 18011.4414\n",
      "Epoch 299/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12851.1223 - mean_absolute_error: 12851.1230 - val_loss: 17928.7027 - val_mean_absolute_error: 17928.7031\n",
      "Epoch 300/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12850.5835 - mean_absolute_error: 12850.5830 - val_loss: 17914.4708 - val_mean_absolute_error: 17914.4707\n",
      "Epoch 301/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12806.8412 - mean_absolute_error: 12806.8408 - val_loss: 17926.1630 - val_mean_absolute_error: 17926.1621\n",
      "Epoch 302/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12846.5025 - mean_absolute_error: 12846.5020 - val_loss: 17985.7859 - val_mean_absolute_error: 17985.7871\n",
      "Epoch 303/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 12814.4250 - mean_absolute_error: 12814.4248 - val_loss: 17963.3815 - val_mean_absolute_error: 17963.3809\n",
      "Epoch 304/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12803.3598 - mean_absolute_error: 12803.3604 - val_loss: 17939.1886 - val_mean_absolute_error: 17939.1875\n",
      "Epoch 305/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12802.2865 - mean_absolute_error: 12802.2852 - val_loss: 17933.6448 - val_mean_absolute_error: 17933.6465\n",
      "Epoch 306/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12794.8174 - mean_absolute_error: 12794.8164 - val_loss: 17934.7249 - val_mean_absolute_error: 17934.7266\n",
      "Epoch 307/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 12805.0314 - mean_absolute_error: 12805.0303 - val_loss: 17926.9628 - val_mean_absolute_error: 17926.9648\n",
      "Epoch 308/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 66us/step - loss: 12790.4489 - mean_absolute_error: 12790.4482 - val_loss: 17940.9246 - val_mean_absolute_error: 17940.9238\n",
      "Epoch 309/500\n",
      "1168/1168 [==============================] - 0s 59us/step - loss: 12811.0771 - mean_absolute_error: 12811.0762 - val_loss: 17955.6474 - val_mean_absolute_error: 17955.6465\n",
      "Epoch 310/500\n",
      "1168/1168 [==============================] - 0s 60us/step - loss: 12775.6303 - mean_absolute_error: 12775.6318 - val_loss: 17957.4387 - val_mean_absolute_error: 17957.4395\n",
      "Epoch 311/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12775.5828 - mean_absolute_error: 12775.5820 - val_loss: 17935.8311 - val_mean_absolute_error: 17935.8320\n",
      "Epoch 312/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 12779.7408 - mean_absolute_error: 12779.7402 - val_loss: 17953.4720 - val_mean_absolute_error: 17953.4727\n",
      "Epoch 313/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 12792.1438 - mean_absolute_error: 12792.1436 - val_loss: 17941.8525 - val_mean_absolute_error: 17941.8535\n",
      "Epoch 314/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 12769.5520 - mean_absolute_error: 12769.5518 - val_loss: 17946.9823 - val_mean_absolute_error: 17946.9824\n",
      "Epoch 315/500\n",
      "1168/1168 [==============================] - 0s 60us/step - loss: 12770.5979 - mean_absolute_error: 12770.5986 - val_loss: 17932.8610 - val_mean_absolute_error: 17932.8594\n",
      "Epoch 316/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12787.2542 - mean_absolute_error: 12787.2539 - val_loss: 17944.6647 - val_mean_absolute_error: 17944.6621\n",
      "Epoch 317/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 12765.9371 - mean_absolute_error: 12765.9355 - val_loss: 17936.8048 - val_mean_absolute_error: 17936.8027\n",
      "Epoch 318/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 12776.8176 - mean_absolute_error: 12776.8164 - val_loss: 17933.3187 - val_mean_absolute_error: 17933.3184\n",
      "Epoch 319/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 12803.2421 - mean_absolute_error: 12803.2432 - val_loss: 17930.8858 - val_mean_absolute_error: 17930.8867\n",
      "Epoch 320/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12753.1379 - mean_absolute_error: 12753.1387 - val_loss: 17958.4312 - val_mean_absolute_error: 17958.4336\n",
      "Epoch 321/500\n",
      "1168/1168 [==============================] - 0s 59us/step - loss: 12764.8794 - mean_absolute_error: 12764.8779 - val_loss: 17954.2919 - val_mean_absolute_error: 17954.2910\n",
      "Epoch 322/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 12761.2067 - mean_absolute_error: 12761.2100 - val_loss: 18004.0131 - val_mean_absolute_error: 18004.0117\n",
      "Epoch 323/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 12764.1716 - mean_absolute_error: 12764.1738 - val_loss: 17988.5813 - val_mean_absolute_error: 17988.5820\n",
      "Epoch 324/500\n",
      "1168/1168 [==============================] - 0s 60us/step - loss: 12764.3056 - mean_absolute_error: 12764.3057 - val_loss: 17971.3191 - val_mean_absolute_error: 17971.3184\n",
      "Epoch 325/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12749.2189 - mean_absolute_error: 12749.2178 - val_loss: 17942.5504 - val_mean_absolute_error: 17942.5488\n",
      "Epoch 326/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 12746.9182 - mean_absolute_error: 12746.9199 - val_loss: 17938.2122 - val_mean_absolute_error: 17938.2129\n",
      "Epoch 327/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 12748.2416 - mean_absolute_error: 12748.2432 - val_loss: 17939.0650 - val_mean_absolute_error: 17939.0625\n",
      "Epoch 328/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12756.2076 - mean_absolute_error: 12756.2090 - val_loss: 18009.8495 - val_mean_absolute_error: 18009.8477\n",
      "Epoch 329/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12738.3894 - mean_absolute_error: 12738.3877 - val_loss: 17924.4907 - val_mean_absolute_error: 17924.4902\n",
      "Epoch 330/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12739.6560 - mean_absolute_error: 12739.6562 - val_loss: 17909.2540 - val_mean_absolute_error: 17909.2539\n",
      "Epoch 331/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12745.1861 - mean_absolute_error: 12745.1836 - val_loss: 17953.2538 - val_mean_absolute_error: 17953.2539\n",
      "Epoch 332/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12742.8770 - mean_absolute_error: 12742.8779 - val_loss: 17935.7197 - val_mean_absolute_error: 17935.7188\n",
      "Epoch 333/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 12739.1955 - mean_absolute_error: 12739.1963 - val_loss: 17962.6012 - val_mean_absolute_error: 17962.6016\n",
      "Epoch 334/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 12735.6099 - mean_absolute_error: 12735.6094 - val_loss: 17934.3231 - val_mean_absolute_error: 17934.3223\n",
      "Epoch 335/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12727.5442 - mean_absolute_error: 12727.5479 - val_loss: 17949.2900 - val_mean_absolute_error: 17949.2910\n",
      "Epoch 336/500\n",
      "1168/1168 [==============================] - 0s 76us/step - loss: 12728.6774 - mean_absolute_error: 12728.6797 - val_loss: 17941.3730 - val_mean_absolute_error: 17941.3730\n",
      "Epoch 337/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 12731.2816 - mean_absolute_error: 12731.2812 - val_loss: 17977.2118 - val_mean_absolute_error: 17977.2129\n",
      "Epoch 338/500\n",
      "1168/1168 [==============================] - 0s 56us/step - loss: 12718.5410 - mean_absolute_error: 12718.5400 - val_loss: 17961.1846 - val_mean_absolute_error: 17961.1836\n",
      "Epoch 339/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12721.0868 - mean_absolute_error: 12721.0869 - val_loss: 17952.5986 - val_mean_absolute_error: 17952.5996\n",
      "Epoch 340/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 12715.6682 - mean_absolute_error: 12715.6670 - val_loss: 17938.3921 - val_mean_absolute_error: 17938.3926\n",
      "Epoch 341/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12721.4344 - mean_absolute_error: 12721.4346 - val_loss: 18001.0474 - val_mean_absolute_error: 18001.0469\n",
      "Epoch 342/500\n",
      "1168/1168 [==============================] - 0s 60us/step - loss: 12729.0263 - mean_absolute_error: 12729.0264 - val_loss: 17942.1596 - val_mean_absolute_error: 17942.1602\n",
      "Epoch 343/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 12710.8498 - mean_absolute_error: 12710.8457 - val_loss: 17975.5761 - val_mean_absolute_error: 17975.5762\n",
      "Epoch 344/500\n",
      "1168/1168 [==============================] - 0s 76us/step - loss: 12705.1850 - mean_absolute_error: 12705.1875 - val_loss: 17992.6796 - val_mean_absolute_error: 17992.6797\n",
      "Epoch 345/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12717.0743 - mean_absolute_error: 12717.0742 - val_loss: 17944.8879 - val_mean_absolute_error: 17944.8887\n",
      "Epoch 346/500\n",
      "1168/1168 [==============================] - 0s 60us/step - loss: 12703.7250 - mean_absolute_error: 12703.7246 - val_loss: 17952.2230 - val_mean_absolute_error: 17952.2227\n",
      "Epoch 347/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12705.5202 - mean_absolute_error: 12705.5225 - val_loss: 17944.0005 - val_mean_absolute_error: 17943.9980\n",
      "Epoch 348/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 12707.3228 - mean_absolute_error: 12707.3232 - val_loss: 17993.8630 - val_mean_absolute_error: 17993.8613\n",
      "Epoch 349/500\n",
      "1168/1168 [==============================] - 0s 59us/step - loss: 12724.2153 - mean_absolute_error: 12724.2168 - val_loss: 17950.3443 - val_mean_absolute_error: 17950.3418\n",
      "Epoch 350/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12717.4068 - mean_absolute_error: 12717.4072 - val_loss: 17982.9621 - val_mean_absolute_error: 17982.9648\n",
      "Epoch 351/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12698.7550 - mean_absolute_error: 12698.7539 - val_loss: 17948.9312 - val_mean_absolute_error: 17948.9316\n",
      "Epoch 352/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 65us/step - loss: 12686.7290 - mean_absolute_error: 12686.7295 - val_loss: 17939.0383 - val_mean_absolute_error: 17939.0391\n",
      "Epoch 353/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12702.0405 - mean_absolute_error: 12702.0391 - val_loss: 17996.3397 - val_mean_absolute_error: 17996.3398\n",
      "Epoch 354/500\n",
      "1168/1168 [==============================] - 0s 56us/step - loss: 12712.5978 - mean_absolute_error: 12712.5986 - val_loss: 17941.3862 - val_mean_absolute_error: 17941.3867\n",
      "Epoch 355/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 12683.0322 - mean_absolute_error: 12683.0322 - val_loss: 17969.7969 - val_mean_absolute_error: 17969.7969\n",
      "Epoch 356/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 12686.8168 - mean_absolute_error: 12686.8184 - val_loss: 17949.6751 - val_mean_absolute_error: 17949.6738\n",
      "Epoch 357/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 12712.3642 - mean_absolute_error: 12712.3643 - val_loss: 18025.5773 - val_mean_absolute_error: 18025.5762\n",
      "Epoch 358/500\n",
      "1168/1168 [==============================] - 0s 88us/step - loss: 12686.0343 - mean_absolute_error: 12686.0342 - val_loss: 17974.7604 - val_mean_absolute_error: 17974.7598\n",
      "Epoch 359/500\n",
      "1168/1168 [==============================] - 0s 52us/step - loss: 12687.4281 - mean_absolute_error: 12687.4277 - val_loss: 17948.5162 - val_mean_absolute_error: 17948.5156\n",
      "Epoch 360/500\n",
      "1168/1168 [==============================] - 0s 56us/step - loss: 12685.8347 - mean_absolute_error: 12685.8330 - val_loss: 17968.6061 - val_mean_absolute_error: 17968.6035\n",
      "Epoch 361/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12678.4874 - mean_absolute_error: 12678.4883 - val_loss: 17976.8881 - val_mean_absolute_error: 17976.8887\n",
      "Epoch 362/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 12683.7163 - mean_absolute_error: 12683.7168 - val_loss: 17969.7216 - val_mean_absolute_error: 17969.7207\n",
      "Epoch 363/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 12683.2623 - mean_absolute_error: 12683.2617 - val_loss: 18001.7293 - val_mean_absolute_error: 18001.7285\n",
      "Epoch 364/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12672.0701 - mean_absolute_error: 12672.0703 - val_loss: 17966.1781 - val_mean_absolute_error: 17966.1797\n",
      "Epoch 365/500\n",
      "1168/1168 [==============================] - 0s 59us/step - loss: 12668.3623 - mean_absolute_error: 12668.3623 - val_loss: 17995.7712 - val_mean_absolute_error: 17995.7715\n",
      "Epoch 366/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12686.2913 - mean_absolute_error: 12686.2881 - val_loss: 18002.0131 - val_mean_absolute_error: 18002.0137\n",
      "Epoch 367/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12657.9050 - mean_absolute_error: 12657.9053 - val_loss: 17983.8849 - val_mean_absolute_error: 17983.8828\n",
      "Epoch 368/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 12669.4959 - mean_absolute_error: 12669.4961 - val_loss: 17966.9426 - val_mean_absolute_error: 17966.9414\n",
      "Epoch 369/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12653.5996 - mean_absolute_error: 12653.5986 - val_loss: 18004.1149 - val_mean_absolute_error: 18004.1152\n",
      "Epoch 370/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 12687.8983 - mean_absolute_error: 12687.8984 - val_loss: 17957.3505 - val_mean_absolute_error: 17957.3516\n",
      "Epoch 371/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12661.2185 - mean_absolute_error: 12661.2188 - val_loss: 17981.6503 - val_mean_absolute_error: 17981.6484\n",
      "Epoch 372/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12656.4385 - mean_absolute_error: 12656.4404 - val_loss: 17946.3906 - val_mean_absolute_error: 17946.3926\n",
      "Epoch 373/500\n",
      "1168/1168 [==============================] - 0s 60us/step - loss: 12633.8433 - mean_absolute_error: 12633.8457 - val_loss: 17980.2108 - val_mean_absolute_error: 17980.2090\n",
      "Epoch 374/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 12645.8579 - mean_absolute_error: 12645.8574 - val_loss: 17952.2958 - val_mean_absolute_error: 17952.2969\n",
      "Epoch 375/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 12653.5119 - mean_absolute_error: 12653.5127 - val_loss: 17940.9054 - val_mean_absolute_error: 17940.9062\n",
      "Epoch 376/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 12669.6088 - mean_absolute_error: 12669.6074 - val_loss: 17964.9474 - val_mean_absolute_error: 17964.9492\n",
      "Epoch 377/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 12646.9395 - mean_absolute_error: 12646.9395 - val_loss: 17953.5830 - val_mean_absolute_error: 17953.5840\n",
      "Epoch 378/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 12685.0062 - mean_absolute_error: 12685.0049 - val_loss: 17944.1888 - val_mean_absolute_error: 17944.1895\n",
      "Epoch 379/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 12648.9733 - mean_absolute_error: 12648.9727 - val_loss: 17969.8406 - val_mean_absolute_error: 17969.8398\n",
      "Epoch 380/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 12645.9358 - mean_absolute_error: 12645.9365 - val_loss: 18003.1246 - val_mean_absolute_error: 18003.1250\n",
      "Epoch 381/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 12637.0807 - mean_absolute_error: 12637.0811 - val_loss: 17970.7833 - val_mean_absolute_error: 17970.7852\n",
      "Epoch 382/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12641.4830 - mean_absolute_error: 12641.4824 - val_loss: 17946.1486 - val_mean_absolute_error: 17946.1484\n",
      "Epoch 383/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12644.3274 - mean_absolute_error: 12644.3262 - val_loss: 18009.4623 - val_mean_absolute_error: 18009.4648\n",
      "Epoch 384/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12637.9401 - mean_absolute_error: 12637.9385 - val_loss: 18015.8678 - val_mean_absolute_error: 18015.8672\n",
      "Epoch 385/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 12646.0211 - mean_absolute_error: 12646.0205 - val_loss: 18001.5494 - val_mean_absolute_error: 18001.5488\n",
      "Epoch 386/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12636.7687 - mean_absolute_error: 12636.7695 - val_loss: 17950.4642 - val_mean_absolute_error: 17950.4648\n",
      "Epoch 387/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12633.3099 - mean_absolute_error: 12633.3105 - val_loss: 17981.6656 - val_mean_absolute_error: 17981.6641\n",
      "Epoch 388/500\n",
      "1168/1168 [==============================] - 0s 56us/step - loss: 12625.1418 - mean_absolute_error: 12625.1406 - val_loss: 18012.5306 - val_mean_absolute_error: 18012.5293\n",
      "Epoch 389/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12620.2764 - mean_absolute_error: 12620.2754 - val_loss: 17939.1655 - val_mean_absolute_error: 17939.1641\n",
      "Epoch 390/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12643.5969 - mean_absolute_error: 12643.5967 - val_loss: 17979.5789 - val_mean_absolute_error: 17979.5781\n",
      "Epoch 391/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 12626.3105 - mean_absolute_error: 12626.3086 - val_loss: 17977.0582 - val_mean_absolute_error: 17977.0586\n",
      "Epoch 392/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 12625.8800 - mean_absolute_error: 12625.8789 - val_loss: 17990.3835 - val_mean_absolute_error: 17990.3828\n",
      "Epoch 393/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12617.0006 - mean_absolute_error: 12617.0020 - val_loss: 17956.6369 - val_mean_absolute_error: 17956.6367\n",
      "Epoch 394/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 12631.9558 - mean_absolute_error: 12631.9551 - val_loss: 18024.9442 - val_mean_absolute_error: 18024.9434\n",
      "Epoch 395/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12634.7163 - mean_absolute_error: 12634.7168 - val_loss: 17975.2887 - val_mean_absolute_error: 17975.2891\n",
      "Epoch 396/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 68us/step - loss: 12618.9300 - mean_absolute_error: 12618.9277 - val_loss: 17979.6026 - val_mean_absolute_error: 17979.6035\n",
      "Epoch 397/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 12629.5696 - mean_absolute_error: 12629.5693 - val_loss: 17960.4044 - val_mean_absolute_error: 17960.4043\n",
      "Epoch 398/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 12641.0350 - mean_absolute_error: 12641.0361 - val_loss: 17947.4507 - val_mean_absolute_error: 17947.4512\n",
      "Epoch 399/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12614.2565 - mean_absolute_error: 12614.2568 - val_loss: 17996.0431 - val_mean_absolute_error: 17996.0469\n",
      "Epoch 400/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 12624.3317 - mean_absolute_error: 12624.3291 - val_loss: 18029.1461 - val_mean_absolute_error: 18029.1465\n",
      "Epoch 401/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12607.8459 - mean_absolute_error: 12607.8467 - val_loss: 17963.9181 - val_mean_absolute_error: 17963.9199\n",
      "Epoch 402/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12613.6116 - mean_absolute_error: 12613.6113 - val_loss: 17994.1567 - val_mean_absolute_error: 17994.1582\n",
      "Epoch 403/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 12614.1886 - mean_absolute_error: 12614.1875 - val_loss: 18004.3146 - val_mean_absolute_error: 18004.3125\n",
      "Epoch 404/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 12607.7492 - mean_absolute_error: 12607.7490 - val_loss: 17955.9843 - val_mean_absolute_error: 17955.9863\n",
      "Epoch 405/500\n",
      "1168/1168 [==============================] - 0s 75us/step - loss: 12610.8023 - mean_absolute_error: 12610.8018 - val_loss: 17970.2567 - val_mean_absolute_error: 17970.2578\n",
      "Epoch 406/500\n",
      "1168/1168 [==============================] - 0s 59us/step - loss: 12595.5633 - mean_absolute_error: 12595.5645 - val_loss: 17942.0729 - val_mean_absolute_error: 17942.0742\n",
      "Epoch 407/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 12608.6486 - mean_absolute_error: 12608.6484 - val_loss: 17937.6475 - val_mean_absolute_error: 17937.6465\n",
      "Epoch 408/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12659.1718 - mean_absolute_error: 12659.1738 - val_loss: 17953.2877 - val_mean_absolute_error: 17953.2871\n",
      "Epoch 409/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 12600.8759 - mean_absolute_error: 12600.8760 - val_loss: 18039.6909 - val_mean_absolute_error: 18039.6895\n",
      "Epoch 410/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 12593.3467 - mean_absolute_error: 12593.3486 - val_loss: 17963.6752 - val_mean_absolute_error: 17963.6758\n",
      "Epoch 411/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12617.7130 - mean_absolute_error: 12617.7119 - val_loss: 18006.3019 - val_mean_absolute_error: 18006.3008\n",
      "Epoch 412/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12601.0654 - mean_absolute_error: 12601.0664 - val_loss: 17963.8051 - val_mean_absolute_error: 17963.8047\n",
      "Epoch 413/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 12589.9664 - mean_absolute_error: 12589.9648 - val_loss: 17957.2147 - val_mean_absolute_error: 17957.2129\n",
      "Epoch 414/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 12592.2055 - mean_absolute_error: 12592.2051 - val_loss: 17984.5729 - val_mean_absolute_error: 17984.5742\n",
      "Epoch 415/500\n",
      "1168/1168 [==============================] - 0s 60us/step - loss: 12611.6834 - mean_absolute_error: 12611.6836 - val_loss: 17977.4493 - val_mean_absolute_error: 17977.4492\n",
      "Epoch 416/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 12593.8468 - mean_absolute_error: 12593.8477 - val_loss: 17957.1682 - val_mean_absolute_error: 17957.1680\n",
      "Epoch 417/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 12590.5429 - mean_absolute_error: 12590.5430 - val_loss: 17943.2507 - val_mean_absolute_error: 17943.2500\n",
      "Epoch 418/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 12587.3905 - mean_absolute_error: 12587.3906 - val_loss: 17983.2185 - val_mean_absolute_error: 17983.2207\n",
      "Epoch 419/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 12587.2025 - mean_absolute_error: 12587.2012 - val_loss: 17981.9353 - val_mean_absolute_error: 17981.9375\n",
      "Epoch 420/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12575.9649 - mean_absolute_error: 12575.9658 - val_loss: 17978.6015 - val_mean_absolute_error: 17978.6016\n",
      "Epoch 421/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12597.9578 - mean_absolute_error: 12597.9580 - val_loss: 18016.3094 - val_mean_absolute_error: 18016.3105\n",
      "Epoch 422/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 12585.8939 - mean_absolute_error: 12585.8936 - val_loss: 17953.5917 - val_mean_absolute_error: 17953.5918\n",
      "Epoch 423/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 12582.1020 - mean_absolute_error: 12582.1025 - val_loss: 17982.0180 - val_mean_absolute_error: 17982.0195\n",
      "Epoch 424/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 12567.8625 - mean_absolute_error: 12567.8613 - val_loss: 18009.3638 - val_mean_absolute_error: 18009.3652\n",
      "Epoch 425/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12591.9423 - mean_absolute_error: 12591.9443 - val_loss: 17963.4349 - val_mean_absolute_error: 17963.4336\n",
      "Epoch 426/500\n",
      "1168/1168 [==============================] - 0s 58us/step - loss: 12562.4756 - mean_absolute_error: 12562.4756 - val_loss: 17960.3204 - val_mean_absolute_error: 17960.3203\n",
      "Epoch 427/500\n",
      "1168/1168 [==============================] - 0s 58us/step - loss: 12571.8423 - mean_absolute_error: 12571.8408 - val_loss: 17990.3233 - val_mean_absolute_error: 17990.3262\n",
      "Epoch 428/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 12563.8656 - mean_absolute_error: 12563.8662 - val_loss: 17992.8467 - val_mean_absolute_error: 17992.8457\n",
      "Epoch 429/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12576.5427 - mean_absolute_error: 12576.5439 - val_loss: 18024.1919 - val_mean_absolute_error: 18024.1934\n",
      "Epoch 430/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 12629.4715 - mean_absolute_error: 12629.4727 - val_loss: 18019.0456 - val_mean_absolute_error: 18019.0449\n",
      "Epoch 431/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12583.1096 - mean_absolute_error: 12583.1113 - val_loss: 17970.6108 - val_mean_absolute_error: 17970.6094\n",
      "Epoch 432/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12585.4076 - mean_absolute_error: 12585.4062 - val_loss: 17945.9954 - val_mean_absolute_error: 17945.9961\n",
      "Epoch 433/500\n",
      "1168/1168 [==============================] - 0s 57us/step - loss: 12615.0644 - mean_absolute_error: 12615.0645 - val_loss: 17943.8122 - val_mean_absolute_error: 17943.8125\n",
      "Epoch 434/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12583.1858 - mean_absolute_error: 12583.1846 - val_loss: 17959.2079 - val_mean_absolute_error: 17959.2090\n",
      "Epoch 435/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12566.3078 - mean_absolute_error: 12566.3076 - val_loss: 17974.9133 - val_mean_absolute_error: 17974.9141\n",
      "Epoch 436/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 12574.6229 - mean_absolute_error: 12574.6240 - val_loss: 17981.4134 - val_mean_absolute_error: 17981.4121\n",
      "Epoch 437/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 12566.4154 - mean_absolute_error: 12566.4150 - val_loss: 17974.4726 - val_mean_absolute_error: 17974.4727\n",
      "Epoch 438/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12566.5906 - mean_absolute_error: 12566.5898 - val_loss: 17965.7702 - val_mean_absolute_error: 17965.7695\n",
      "Epoch 439/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 12619.3219 - mean_absolute_error: 12619.3232 - val_loss: 17990.9803 - val_mean_absolute_error: 17990.9785\n",
      "Epoch 440/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 64us/step - loss: 12569.2049 - mean_absolute_error: 12569.2051 - val_loss: 18030.1304 - val_mean_absolute_error: 18030.1309\n",
      "Epoch 441/500\n",
      "1168/1168 [==============================] - 0s 59us/step - loss: 12567.1518 - mean_absolute_error: 12567.1514 - val_loss: 18008.3193 - val_mean_absolute_error: 18008.3184\n",
      "Epoch 442/500\n",
      "1168/1168 [==============================] - 0s 58us/step - loss: 12564.2727 - mean_absolute_error: 12564.2734 - val_loss: 18004.3841 - val_mean_absolute_error: 18004.3828\n",
      "Epoch 443/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 12554.2097 - mean_absolute_error: 12554.2090 - val_loss: 18000.1379 - val_mean_absolute_error: 18000.1387\n",
      "Epoch 444/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 12553.1653 - mean_absolute_error: 12553.1621 - val_loss: 18017.3264 - val_mean_absolute_error: 18017.3262\n",
      "Epoch 445/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 12543.2902 - mean_absolute_error: 12543.2910 - val_loss: 18061.0186 - val_mean_absolute_error: 18061.0176\n",
      "Epoch 446/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12591.3809 - mean_absolute_error: 12591.3799 - val_loss: 17962.2382 - val_mean_absolute_error: 17962.2363\n",
      "Epoch 447/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 12544.3055 - mean_absolute_error: 12544.3037 - val_loss: 18020.3583 - val_mean_absolute_error: 18020.3574\n",
      "Epoch 448/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12546.4194 - mean_absolute_error: 12546.4189 - val_loss: 18001.4193 - val_mean_absolute_error: 18001.4219\n",
      "Epoch 449/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12585.8020 - mean_absolute_error: 12585.8027 - val_loss: 17975.2514 - val_mean_absolute_error: 17975.2539\n",
      "Epoch 450/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 12540.0372 - mean_absolute_error: 12540.0371 - val_loss: 18011.2711 - val_mean_absolute_error: 18011.2715\n",
      "Epoch 451/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12540.0181 - mean_absolute_error: 12540.0166 - val_loss: 18026.0379 - val_mean_absolute_error: 18026.0371\n",
      "Epoch 452/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12543.6095 - mean_absolute_error: 12543.6074 - val_loss: 17972.0582 - val_mean_absolute_error: 17972.0586\n",
      "Epoch 453/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 12553.2209 - mean_absolute_error: 12553.2246 - val_loss: 18009.7227 - val_mean_absolute_error: 18009.7227\n",
      "Epoch 454/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 12552.3080 - mean_absolute_error: 12552.3096 - val_loss: 18003.1054 - val_mean_absolute_error: 18003.1035\n",
      "Epoch 455/500\n",
      "1168/1168 [==============================] - 0s 73us/step - loss: 12522.9355 - mean_absolute_error: 12522.9355 - val_loss: 18068.1600 - val_mean_absolute_error: 18068.1602\n",
      "Epoch 456/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12554.4061 - mean_absolute_error: 12554.4062 - val_loss: 18021.2379 - val_mean_absolute_error: 18021.2363\n",
      "Epoch 457/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12533.2873 - mean_absolute_error: 12533.2871 - val_loss: 17982.1077 - val_mean_absolute_error: 17982.1094\n",
      "Epoch 458/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12574.0873 - mean_absolute_error: 12574.0879 - val_loss: 18061.8954 - val_mean_absolute_error: 18061.8965\n",
      "Epoch 459/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 12602.8280 - mean_absolute_error: 12602.8311 - val_loss: 18019.2367 - val_mean_absolute_error: 18019.2383\n",
      "Epoch 460/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12531.9470 - mean_absolute_error: 12531.9463 - val_loss: 18061.8797 - val_mean_absolute_error: 18061.8809\n",
      "Epoch 461/500\n",
      "1168/1168 [==============================] - 0s 78us/step - loss: 12535.9457 - mean_absolute_error: 12535.9463 - val_loss: 17977.9281 - val_mean_absolute_error: 17977.9277\n",
      "Epoch 462/500\n",
      "1168/1168 [==============================] - 0s 68us/step - loss: 12548.8682 - mean_absolute_error: 12548.8682 - val_loss: 17980.5416 - val_mean_absolute_error: 17980.5410\n",
      "Epoch 463/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12528.8386 - mean_absolute_error: 12528.8389 - val_loss: 18040.3185 - val_mean_absolute_error: 18040.3184\n",
      "Epoch 464/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12531.4677 - mean_absolute_error: 12531.4688 - val_loss: 17993.0749 - val_mean_absolute_error: 17993.0762\n",
      "Epoch 465/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12528.9102 - mean_absolute_error: 12528.9102 - val_loss: 18016.3165 - val_mean_absolute_error: 18016.3145\n",
      "Epoch 466/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12526.4842 - mean_absolute_error: 12526.4854 - val_loss: 17960.8327 - val_mean_absolute_error: 17960.8320\n",
      "Epoch 467/500\n",
      "1168/1168 [==============================] - 0s 71us/step - loss: 12539.8720 - mean_absolute_error: 12539.8730 - val_loss: 18045.0916 - val_mean_absolute_error: 18045.0898\n",
      "Epoch 468/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12610.1122 - mean_absolute_error: 12610.1123 - val_loss: 18094.3987 - val_mean_absolute_error: 18094.3984\n",
      "Epoch 469/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12535.6527 - mean_absolute_error: 12535.6553 - val_loss: 18005.0353 - val_mean_absolute_error: 18005.0352\n",
      "Epoch 470/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 12519.4609 - mean_absolute_error: 12519.4619 - val_loss: 18012.2876 - val_mean_absolute_error: 18012.2871\n",
      "Epoch 471/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12511.1638 - mean_absolute_error: 12511.1641 - val_loss: 17996.2062 - val_mean_absolute_error: 17996.2051\n",
      "Epoch 472/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12512.8224 - mean_absolute_error: 12512.8232 - val_loss: 18000.5176 - val_mean_absolute_error: 18000.5215\n",
      "Epoch 473/500\n",
      "1168/1168 [==============================] - 0s 64us/step - loss: 12520.5175 - mean_absolute_error: 12520.5176 - val_loss: 18000.9896 - val_mean_absolute_error: 18000.9902\n",
      "Epoch 474/500\n",
      "1168/1168 [==============================] - 0s 69us/step - loss: 12521.9518 - mean_absolute_error: 12521.9512 - val_loss: 17989.0216 - val_mean_absolute_error: 17989.0215\n",
      "Epoch 475/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 12507.3529 - mean_absolute_error: 12507.3525 - val_loss: 17977.6174 - val_mean_absolute_error: 17977.6172\n",
      "Epoch 476/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 12516.0520 - mean_absolute_error: 12516.0518 - val_loss: 17993.8218 - val_mean_absolute_error: 17993.8203\n",
      "Epoch 477/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 12508.7724 - mean_absolute_error: 12508.7734 - val_loss: 17983.5800 - val_mean_absolute_error: 17983.5781\n",
      "Epoch 478/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 12508.2185 - mean_absolute_error: 12508.2188 - val_loss: 17990.4476 - val_mean_absolute_error: 17990.4492\n",
      "Epoch 479/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 12499.9079 - mean_absolute_error: 12499.9072 - val_loss: 17976.6385 - val_mean_absolute_error: 17976.6387\n",
      "Epoch 480/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 12546.0788 - mean_absolute_error: 12546.0791 - val_loss: 17977.8936 - val_mean_absolute_error: 17977.8926\n",
      "Epoch 481/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 12512.4684 - mean_absolute_error: 12512.4678 - val_loss: 17990.3334 - val_mean_absolute_error: 17990.3320\n",
      "Epoch 482/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12536.0486 - mean_absolute_error: 12536.0498 - val_loss: 18037.1719 - val_mean_absolute_error: 18037.1719\n",
      "Epoch 483/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12510.8904 - mean_absolute_error: 12510.8916 - val_loss: 17997.4196 - val_mean_absolute_error: 17997.4180\n",
      "Epoch 484/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 62us/step - loss: 12493.9715 - mean_absolute_error: 12493.9736 - val_loss: 18005.6477 - val_mean_absolute_error: 18005.6484\n",
      "Epoch 485/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12499.0912 - mean_absolute_error: 12499.0938 - val_loss: 18010.8459 - val_mean_absolute_error: 18010.8438\n",
      "Epoch 486/500\n",
      "1168/1168 [==============================] - 0s 60us/step - loss: 12495.2730 - mean_absolute_error: 12495.2744 - val_loss: 18045.3628 - val_mean_absolute_error: 18045.3633\n",
      "Epoch 487/500\n",
      "1168/1168 [==============================] - 0s 67us/step - loss: 12501.5125 - mean_absolute_error: 12501.5117 - val_loss: 18033.6595 - val_mean_absolute_error: 18033.6602\n",
      "Epoch 488/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 12506.1053 - mean_absolute_error: 12506.1074 - val_loss: 18027.8685 - val_mean_absolute_error: 18027.8672\n",
      "Epoch 489/500\n",
      "1168/1168 [==============================] - 0s 63us/step - loss: 12484.0969 - mean_absolute_error: 12484.0957 - val_loss: 18032.8348 - val_mean_absolute_error: 18032.8359\n",
      "Epoch 490/500\n",
      "1168/1168 [==============================] - 0s 60us/step - loss: 12502.5057 - mean_absolute_error: 12502.5049 - val_loss: 18032.2475 - val_mean_absolute_error: 18032.2480\n",
      "Epoch 491/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 12488.5561 - mean_absolute_error: 12488.5566 - val_loss: 18032.6626 - val_mean_absolute_error: 18032.6621\n",
      "Epoch 492/500\n",
      "1168/1168 [==============================] - 0s 65us/step - loss: 12488.1839 - mean_absolute_error: 12488.1836 - val_loss: 18014.3688 - val_mean_absolute_error: 18014.3672\n",
      "Epoch 493/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 12485.6263 - mean_absolute_error: 12485.6289 - val_loss: 18063.2920 - val_mean_absolute_error: 18063.2891\n",
      "Epoch 494/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12480.7785 - mean_absolute_error: 12480.7793 - val_loss: 18029.0408 - val_mean_absolute_error: 18029.0410\n",
      "Epoch 495/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12480.1092 - mean_absolute_error: 12480.1094 - val_loss: 18026.4765 - val_mean_absolute_error: 18026.4785\n",
      "Epoch 496/500\n",
      "1168/1168 [==============================] - 0s 66us/step - loss: 12490.2815 - mean_absolute_error: 12490.2803 - val_loss: 18085.3814 - val_mean_absolute_error: 18085.3828\n",
      "Epoch 497/500\n",
      "1168/1168 [==============================] - 0s 62us/step - loss: 12503.9048 - mean_absolute_error: 12503.9043 - val_loss: 18038.7095 - val_mean_absolute_error: 18038.7109\n",
      "Epoch 498/500\n",
      "1168/1168 [==============================] - 0s 72us/step - loss: 12497.4870 - mean_absolute_error: 12497.4883 - val_loss: 18023.0314 - val_mean_absolute_error: 18023.0312\n",
      "Epoch 499/500\n",
      "1168/1168 [==============================] - 0s 61us/step - loss: 12473.5715 - mean_absolute_error: 12473.5703 - val_loss: 18026.0216 - val_mean_absolute_error: 18026.0195\n",
      "Epoch 500/500\n",
      "1168/1168 [==============================] - 0s 70us/step - loss: 12491.2334 - mean_absolute_error: 12491.2324 - val_loss: 18038.5138 - val_mean_absolute_error: 18038.5156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1e672eb3908>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=500,batch_size=32,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preproc = full_Pipeline.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_1_input to have shape (289,) but got array with shape (271,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-75a637d6131e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_test_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_preproc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[1;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1441\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1442\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1443\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    143\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_1_input to have shape (289,) but got array with shape (271,)"
     ]
    }
   ],
   "source": [
    "y_test_hat = model.predict(test_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
